{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing MC Env Learning in 2 v 2 environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constants and loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "\n",
    "from vgc.datatypes.Objects import PkmTeam, Pkm, GameState, Weather\n",
    "from vgc.engine.PkmBattleEnv import PkmBattleEnv\n",
    "from vgc.util.generator.PkmTeamGenerators import RandomTeamGenerator\n",
    "\n",
    "from vgc.datatypes.Constants import TYPE_CHART_MULTIPLIER, MAX_HIT_POINTS, MOVE_MAX_PP, DEFAULT_TEAM_SIZE\n",
    "from vgc.datatypes.Objects import PkmMove, Pkm, PkmTeam, GameState, Weather\n",
    "from vgc.datatypes.Types import PkmStat, PkmType, WeatherCondition, \\\n",
    "    N_TYPES, N_STATUS, N_STATS, N_ENTRY_HAZARD, N_WEATHER, PkmStatus, PkmEntryHazard\n",
    "\n",
    "\n",
    "import pprint\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nneed to turn the states into the dict\\n    TEST want to store counts and running mean of the reward\\n\\nset up the evaluation loop for this agent vs. the base always attack agent\\n\\nTEST need to test how many battles can get through in how much time\\n\\nTEST saving the action dict\\n\\nTEST need to select the initial action\\nTEST need to then to attack later\\nTEST need to convert the attack action into the best attack\\nTEST need to convert the swap action into a swap\\nTEST need to store the result of the battle\\nTEST convert outcome into a rewards\\n\\nLater\\n\\nfunctionalize the build dict loop\\nfunctionalize the eval\\ncan run the dict and eval in python files\\ncan parallelize the dict building\\n\\nmaybe store all states in a list then to the dict\\n    works I think as long as all actions past that point are attacks\\n    could then combine that later with a swap at that point maybe?\\n        idk maybe not... could be the 2nd swap and then things are necessarily clear\\n            ie initial pkm has been revealed and may have taken dmg (though maybe that doesn't matter)\\n\\npossibly store the state dict attack action for non first actions as well\\n\\n            \\nneed to add the hiding part\\n    i guess it's more like some states don't know opp dmg to current pkm and sometimes do\\n\\n    maybe parallelize if any of this works\\n\\n\\ncan I get the best dmg from both teams even if the pkm stuff is hidden and not revealed?\\n    probably yes since passing in the team specific state\\n\\ncan check to see how accurate the attack function is\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "grab the value from the lookup dict and see if can be used\n",
    "\n",
    "DRY for the two loops\n",
    "\n",
    "review flow of all code\n",
    "\n",
    "reveiw and test all parts of the code\n",
    "\n",
    "can this be generalized more?\n",
    "    ie not just for the first move when eval but any move?\n",
    "    idk, probably not for now\n",
    "\n",
    "due to the variability in outcomes I think I need a ton of results to tell if swap is better or not\n",
    "    like 1000 for each state and since like 500,000 states that is 500,000,000 battles\n",
    "\n",
    "TEST need to turn the states into the dict\n",
    "    TEST want to store counts and running mean of the reward\n",
    "\n",
    "TEST set up the evaluation loop for this agent vs. the base always attack agent\n",
    "\n",
    "TEST need to test how many battles can get through in how much time\n",
    "\n",
    "TEST saving the action dict\n",
    "\n",
    "TEST need to select the initial action\n",
    "TEST need to then to attack later\n",
    "TEST need to convert the attack action into the best attack\n",
    "TEST need to convert the swap action into a swap\n",
    "TEST need to store the result of the battle\n",
    "TEST convert outcome into a rewards\n",
    "\n",
    "Later\n",
    "\n",
    "functionalize the build dict loop\n",
    "functionalize the eval\n",
    "can run the dict and eval in python files\n",
    "can parallelize the dict building\n",
    "\n",
    "maybe store all states in a list then to the dict\n",
    "    works I think as long as all actions past that point are attacks\n",
    "    could then combine that later with a swap at that point maybe?\n",
    "        idk maybe not... could be the 2nd swap and then things are necessarily clear\n",
    "            ie initial pkm has been revealed and may have taken dmg (though maybe that doesn't matter)\n",
    "\n",
    "possibly store the state dict attack action for non first actions as well\n",
    "\n",
    "            \n",
    "need to add the hiding part\n",
    "    i guess it's more like some states don't know opp dmg to current pkm and sometimes do\n",
    "\n",
    "    maybe parallelize if any of this works\n",
    "\n",
    "\n",
    "can I get the best dmg from both teams even if the pkm stuff is hidden and not revealed?\n",
    "    probably yes since passing in the team specific state\n",
    "\n",
    "can check to see how accurate the attack function is\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions for Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_agent_action_into_env_action(action, agent_game_state):\n",
    "        '''\n",
    "        Action values are\n",
    "        0: select best move\n",
    "        1: switch to first pkm\n",
    "        2: switch to second pkm\n",
    "\n",
    "        Env actions are\n",
    "        0 to 3: action of active pokm\n",
    "        4: switch to first pkm\n",
    "        5: switch to second pkm\n",
    "        '''\n",
    "        # always get best move and action dmg list\n",
    "        best_active_action, best_damage_list = get_best_active_damage_action(agent_game_state)\n",
    "\n",
    "        if action == 0:\n",
    "            # get best dmg action\n",
    "            action = best_active_action\n",
    "        else:\n",
    "            # switch to first or second pkm if alive\n",
    "            if action == 1 or action == 2:\n",
    "                pkm = agent_game_state.teams[0].party[action-1]\n",
    "                if pkm.fainted() or pkm.hp <= 0.0:\n",
    "                    action = best_active_action\n",
    "                else:\n",
    "                    action = action + 3\n",
    "            else:\n",
    "                action = best_active_action\n",
    "\n",
    "        return action, best_damage_list\n",
    "\n",
    "\n",
    "def get_best_active_damage_action(g: GameState):\n",
    "    '''\n",
    "    '''\n",
    "    # Get weather condition\n",
    "    weather = g.weather.condition\n",
    "\n",
    "    # Get my Pokémon team\n",
    "    my_team = g.teams[0]\n",
    "    my_pkms = [my_team.active] + my_team.party\n",
    "\n",
    "    # Get opponent's team\n",
    "    opp_team = g.teams[1]\n",
    "    opp_active = opp_team.active\n",
    "\n",
    "    opp_active_type = opp_active.type\n",
    "    opp_defense_stage = opp_team.stage[PkmStat.DEFENSE]\n",
    "\n",
    "    # Iterate over all my Pokémon and their moves to find the most damaging move\n",
    "    best_dmg_list = []\n",
    "    best_move_list = []\n",
    "\n",
    "    for i, pkm in enumerate(my_pkms):\n",
    "        # Initialize variables for the best move and its damage\n",
    "        best_damage = -np.inf\n",
    "        best_move_id = -1\n",
    "\n",
    "        if i == 0:\n",
    "            my_attack_stage = my_team.stage[PkmStat.ATTACK]\n",
    "        else:\n",
    "            my_attack_stage = 0\n",
    "\n",
    "        for j, move in enumerate(pkm.moves):\n",
    "            \n",
    "            damage = estimate_damage(move.type, pkm.type, move.power, opp_active_type, my_attack_stage,\n",
    "                                        opp_defense_stage, weather)\n",
    "            \n",
    "            # Check if the current move has higher damage than the previous best move\n",
    "            if damage > best_damage:\n",
    "                best_move_id = j + i * 4 # think for 2024 j is 0 to 3 for each\n",
    "                best_damage = damage\n",
    "\n",
    "        # get best move and dmg for each pokemon\n",
    "        best_dmg_list.append(best_damage)\n",
    "        best_move_list.append(best_move_id)\n",
    "\n",
    "    active_pkm_best_move_id = best_move_list[0]\n",
    "\n",
    "    if active_pkm_best_move_id < 0 or active_pkm_best_move_id > 3:\n",
    "        print(f\"Error: best move id { active_pkm_best_move_id } not in expected range\")\n",
    "        active_pkm_best_move_id = 0\n",
    "\n",
    "    return active_pkm_best_move_id, best_dmg_list\n",
    "\n",
    "\n",
    "def estimate_damage(move_type: PkmType, pkm_type: PkmType, move_power: float, opp_pkm_type: PkmType,\n",
    "                    attack_stage: int, defense_stage: int, weather: WeatherCondition) -> float:\n",
    "        '''\n",
    "        Not from original code. from updated repo\n",
    "        '''\n",
    "        stab = 1.5 if move_type == pkm_type else 1.\n",
    "        if (move_type == PkmType.WATER and weather == WeatherCondition.RAIN) or (\n",
    "                move_type == PkmType.FIRE and weather == WeatherCondition.SUNNY):\n",
    "            weather = 1.5\n",
    "        elif (move_type == PkmType.WATER and weather == WeatherCondition.SUNNY) or (\n",
    "                move_type == PkmType.FIRE and weather == WeatherCondition.RAIN):\n",
    "            weather = .5\n",
    "        else:\n",
    "            weather = 1.\n",
    "        stage_level = attack_stage - defense_stage\n",
    "        stage = (stage_level + 2.) / 2 if stage_level >= 0. else 2. / (np.abs(stage_level) + 2.)\n",
    "        damage = TYPE_CHART_MULTIPLIER[move_type][opp_pkm_type] * stab * weather * stage * move_power\n",
    "\n",
    "        #print(damage, move_type, pkm_type, move_power, opp_pkm_type, attack_stage, defense_stage, weather)\n",
    "        return damage\n",
    "\n",
    "\n",
    "def save_object_as_pkl(object_to_save, save_tag):\n",
    "    '''\n",
    "    Save object a pickle file\n",
    "    '''\n",
    "    with open(f'{save_tag}.pickle', 'wb') as handle:\n",
    "        pickle.dump(object_to_save, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# make a dict that has keys for 0 to 100 and values for the action dict\n",
    "def make_lookup_dict():\n",
    "    lookup_dict = {}\n",
    "    for i in range(100):\n",
    "        if i <= 40:\n",
    "            lookup_value = i // 5\n",
    "        else:\n",
    "            lookup_value = 4 + i // 10\n",
    "        lookup_dict[i] = lookup_value\n",
    "    return lookup_dict\n",
    "\n",
    "# lookup_dict = make_lookup_dict()\n",
    "# pprint.pprint(lookup_dict)\n",
    "\n",
    "def get_win_loss_reward(terminated, winner, player_index):\n",
    "    '''\n",
    "    Does a reward for winning or losing\n",
    "    winner is -1 unless a winner has been picked\n",
    "    '''\n",
    "    reward = 0.\n",
    "    if terminated:\n",
    "\n",
    "        if winner == 0 or winner == 1:\n",
    "            if winner == player_index:\n",
    "                reward = 1.\n",
    "            else:\n",
    "                reward = -1.\n",
    "        #print(f\"reward {reward} | terminated {terminated} | winner {self.env.winner} | player_index {player_index}|\")\n",
    "    return reward\n",
    "\n",
    "def get_running_mean(old_mean, old_count, new_value):\n",
    "    '''\n",
    "    '''\n",
    "    new_mean = (old_mean * old_count + new_value) / (old_count + 1)\n",
    "    \n",
    "    return new_mean\n",
    "\n",
    "\n",
    "def add_results_to_action_dict(action_dict, state_key, agent_first_move, win_int):\n",
    "    '''\n",
    "    '''\n",
    "    count_key = \"count\"\n",
    "    sum_wins_key = \"sum_wins\"\n",
    "\n",
    "    if state_key in action_dict:\n",
    "        if agent_first_move in action_dict[state_key]:\n",
    "            action_dict[state_key][agent_first_move][sum_wins_key] += win_int\n",
    "            action_dict[state_key][agent_first_move][count_key] += 1\n",
    "        else:\n",
    "            action_dict[state_key][agent_first_move] = {}\n",
    "            action_dict[state_key][agent_first_move][sum_wins_key] = win_int\n",
    "            action_dict[state_key][agent_first_move][count_key] = 1\n",
    "    else:\n",
    "        action_dict[state_key] = {}\n",
    "        action_dict[state_key][agent_first_move] = {}\n",
    "        action_dict[state_key][agent_first_move][sum_wins_key] = win_int\n",
    "        action_dict[state_key][agent_first_move][count_key] = 1\n",
    "\n",
    "def add_action_to_pkm_env_action_dict(env_action, my_dict, team_key):\n",
    "    if env_action in my_dict[team_key]:\n",
    "        my_dict[team_key][env_action] += 1\n",
    "    else:\n",
    "        my_dict[team_key][env_action] = 1\n",
    "\n",
    "    return my_dict\n",
    "\n",
    "\n",
    "\n",
    "# def add_results_to_action_dict(action_dict, state_key, agent_first_move, agent_reward):\n",
    "#     '''\n",
    "#     '''\n",
    "#     if state_key in action_dict:\n",
    "#         if agent_first_move in action_dict[state_key]:\n",
    "#             action_dict[state_key][agent_first_move][\"avg_reward\"] = get_running_mean(action_dict[state_key][agent_first_move][\"avg_reward\"],\n",
    "#                                                                                   action_dict[state_key][agent_first_move][\"count\"], agent_reward)\n",
    "#             action_dict[state_key][agent_first_move][\"count\"] += 1\n",
    "#         else:\n",
    "#             action_dict[state_key][agent_first_move] = {}\n",
    "#             action_dict[state_key][agent_first_move][\"avg_reward\"] = agent_reward\n",
    "#             action_dict[state_key][agent_first_move][\"count\"] = 1\n",
    "\n",
    "# a = (1, 2, 3)\n",
    "# type(a)\n",
    "# # combine two tuples\n",
    "# b = a + (4, 5, 6)\n",
    "# b\n",
    "# # append the value 7 to the tuple\n",
    "# b = b + (7,)\n",
    "# b\n",
    "\n",
    "\n",
    "def get_hp_array(game_state_agent, game_state_opp):\n",
    "    '''\n",
    "    '''\n",
    "    agent_pkm_hp_list = [game_state_agent.teams[0].active.hp]\n",
    "\n",
    "    for pkm in game_state_agent.teams[0].party:\n",
    "        agent_pkm_hp_list.append(pkm.hp)\n",
    "\n",
    "    opp_active_pkm_hp = game_state_opp.teams[0].active.hp\n",
    "\n",
    "    hp_array = np.array(agent_pkm_hp_list + [opp_active_pkm_hp])\n",
    "\n",
    "    return hp_array\n",
    "\n",
    "def turn_game_state_into_dict_key(game_state_agent, game_state_opp,lookup_dict,\n",
    "    dmg_array,                      \n",
    "    pkm_hp_max = 480., dmg_scale_value = 600.):\n",
    "    '''\n",
    "    tuple is (\n",
    "        # HP\n",
    "        agent_active_pkm_hp, agent_party+_pkm_hp, opp_active_pkm_hp,\n",
    "        # DMG to opp\n",
    "        agent_active_pkm_dmg, agent_party_pkm_dmg,\n",
    "        # dmg from opp\n",
    "        # do this later\n",
    "        )\n",
    "    \n",
    "    If everything is on the scale of 0 to 100 picturing\n",
    "    8 buckets from 0 to 40 with increments of 5\n",
    "    6 buckets from 40 to 100 with increments of 10\n",
    "\n",
    "    preload a dict with the look up, then scal everything here\n",
    "\n",
    "    scaling dmg more than max hp so if move can do over 480 dmg has some sort of knowledge ofit\n",
    "    '''\n",
    "    # get arrays to make tuples out of for dict key\n",
    "    hp_array = get_hp_array(game_state_agent, game_state_opp)\n",
    "\n",
    "    hp_tuple = scale_hp_and_get_dict_value(hp_array, pkm_hp_max, lookup_dict)\n",
    "    dmg_tuple = scale_hp_and_get_dict_value(dmg_array, dmg_scale_value, lookup_dict)\n",
    "\n",
    "    dict_key = hp_tuple + dmg_tuple\n",
    "\n",
    "    return dict_key\n",
    "\n",
    "\n",
    "def scale_hp_and_get_dict_value(hp_array, max_hp, lookup_dict):\n",
    "    '''\n",
    "    '''\n",
    "\n",
    "    # scale by max hp then multiply by 100 to get into 0 to 99 range\n",
    "    hp_array = (hp_array / max_hp) * 100\n",
    "    # round, convert to int then clip to 0 to 99\n",
    "    hp_array = hp_array.round(0).astype(int).clip(0, 99)\n",
    "\n",
    "    \n",
    "\n",
    "    # for hp in hp_array:\n",
    "    #     hp_values_from_dict_tuple = hp_values_from_dict_tuple + (lookup_dict[hp],)\n",
    "\n",
    "    hp_values_from_dict_tuple = tuple(lookup_dict[hp] for hp in hp_array)\n",
    "\n",
    "    return hp_values_from_dict_tuple\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lookup_dict = make_lookup_dict()\n",
    "\n",
    "# a = turn_game_state_into_dict_key(game_state[0], game_state[1], lookup_dict, dmg_array)\n",
    "\n",
    "# print(a)\n",
    "\n",
    "# a = (1, 2, 3)\n",
    "# type(a)\n",
    "# # combine two tuples\n",
    "# b = a + (4, 5, 6)\n",
    "# b\n",
    "# print(b)\n",
    "# print(type(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Dict Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to run 0.010 minutes\n",
      "Time to run 0.006 seconds per battle\n",
      "Time to run 1.586 hours per million battles\n",
      "{0: 0, 1: 0, -1: 0}\n"
     ]
    }
   ],
   "source": [
    "num_battles = 100\n",
    "\n",
    "winner_dict = {\n",
    "    0:0,\n",
    "    1:0,\n",
    "    -1:0\n",
    "}\n",
    "\n",
    "pkm_env_action_dict = {\n",
    "    0:{},\n",
    "    1:{},\n",
    "}\n",
    "\n",
    "action_state_results_dict = {}\n",
    "\n",
    "max_episode_steps = 250\n",
    "agent_index = 0\n",
    "\n",
    "lookup_dict = make_lookup_dict()\n",
    "team_generator = RandomTeamGenerator(2)\n",
    "\n",
    "time_int = int(time.time())\n",
    "save_tag =  f\"_smoke_test_{time_int}\"\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "for battle_idx in range(num_battles):\n",
    "    \n",
    "    agent_team = team_generator.get_team().get_battle_team([0, 1, ])\n",
    "    opp_team = team_generator.get_team().get_battle_team([0, 1, ])\n",
    "\n",
    "    # set new environment with teams\n",
    "    env = PkmBattleEnv((agent_team, opp_team),\n",
    "                   encode=(False, False)) \n",
    "\n",
    "    game_state, info = env.reset()\n",
    "\n",
    "    is_first_move = True\n",
    "    agent_first_move = None\n",
    "    state_key = None\n",
    "\n",
    "    for episode_step in range(max_episode_steps):\n",
    "        if is_first_move:\n",
    "            if np.random.rand() < 0.5:\n",
    "                agent_pre_env_action = 0\n",
    "                agent_first_move = 'attack'\n",
    "            else:\n",
    "                agent_pre_env_action = 1\n",
    "                agent_first_move = 'swap'\n",
    "            is_first_move = False\n",
    "        else:\n",
    "            agent_pre_env_action = 0\n",
    "\n",
    "        agent_env_action, agent_team_best_damage_list = turn_agent_action_into_env_action(agent_pre_env_action, game_state[0])\n",
    "        opp_action, opp_best_damage_list = get_best_active_damage_action(game_state[1])\n",
    "\n",
    "        if agent_pre_env_action == 1 and agent_env_action != 4:\n",
    "            print(\"Error agent action is 1 but env action is not 4 \")\n",
    "        elif agent_pre_env_action == 0:\n",
    "            if (agent_env_action < 0 or agent_env_action > 3):\n",
    "                print(\"Error agent action is 0 but env action is not 0 to 3 \")\n",
    "            elif len(agent_team_best_damage_list) == 0:\n",
    "                print(\"Error agent action is 0 but best damage list is empty\")\n",
    "            elif agent_team_best_damage_list[0] < 0:\n",
    "                print(\"Error agent action is 0 but best damage is negative\")\n",
    "\n",
    "        if opp_action < 0 or opp_action > 3:\n",
    "            print(\"Error opp action is not 0 to 3\")\n",
    "        elif len(opp_best_damage_list) == 0:\n",
    "            print(\"Error opp best damage list is empty\")\n",
    "        elif opp_best_damage_list[0] < 0:\n",
    "            print(\"Error opp best damage is negative\")\n",
    "        \n",
    "        # get the state key\n",
    "        # only do this on the initial set up of the env\n",
    "        if state_key is None:\n",
    "            # for now just doing part dmg to opp\n",
    "            #dmg_array = np.array(agent_best_damage_list + [opp_best_damage,])\n",
    "            dmg_array = np.array(agent_team_best_damage_list)\n",
    "            state_key = turn_game_state_into_dict_key(game_state[0], game_state[1], lookup_dict, dmg_array)\n",
    "            if len(state_key) != 5:\n",
    "                print(\"Error state key is not 5 long\")\n",
    "\n",
    "        # enter action and step the env\n",
    "        action_list = [agent_env_action, opp_action]\n",
    "        game_state, _not_used_reward, terminated, truncated, info = env.step(action_list)  # for inference, we don't need reward\n",
    "\n",
    "        if episode_step == max_episode_steps - 1:\n",
    "            print('Warning: max steps reached')\n",
    "            terminated = True\n",
    "\n",
    "        if terminated:\n",
    "            winner = env.winner\n",
    "            if winner == agent_index:\n",
    "                win_int = 1\n",
    "            else:\n",
    "                win_int = 0\n",
    "\n",
    "            add_results_to_action_dict(action_state_results_dict, state_key, agent_first_move, win_int)\n",
    "            break\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Time to run {(end_time - start_time) / 60:.3f} minutes\")\n",
    "print(f\"Time to run {(end_time - start_time) / num_battles:.3f} seconds per battle\")\n",
    "print(f\"Time to run {((end_time - start_time) / num_battles / 60 / 60) * 1000000:.3f} hours per million battles\")\n",
    "\n",
    "print(winner_dict)\n",
    "# print(action_dict)\n",
    "\n",
    "\n",
    "save_object_as_pkl(action_state_results_dict , 'action_dict_smoke_test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(action_state_results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(5, 6, 5, 12, 11): {'attack': {'sum_wins': 0, 'count': 1}},\n",
       " (6, 8, 6, 12, 9): {'attack': {'sum_wins': 1, 'count': 1}},\n",
       " (5, 5, 5, 8, 10): {'attack': {'sum_wins': 0, 'count': 1}},\n",
       " (8, 8, 6, 2, 5): {'swap': {'sum_wins': 0, 'count': 1}},\n",
       " (8, 9, 8, 4, 6): {'attack': {'sum_wins': 0, 'count': 1}},\n",
       " (6, 8, 8, 3, 5): {'swap': {'sum_wins': 0, 'count': 1}},\n",
       " (8, 10, 8, 8, 5): {'attack': {'sum_wins': 1, 'count': 1}},\n",
       " (5, 5, 8, 8, 7): {'swap': {'sum_wins': 0, 'count': 1}},\n",
       " (8, 8, 5, 7, 8): {'attack': {'sum_wins': 1, 'count': 1}},\n",
       " (5, 5, 5, 8, 8): {'attack': {'sum_wins': 0, 'count': 1},\n",
       "  'swap': {'sum_wins': 0, 'count': 1}},\n",
       " (5, 6, 5, 9, 8): {'swap': {'sum_wins': 0, 'count': 1}},\n",
       " (10, 8, 8, 3, 3): {'attack': {'sum_wins': 0, 'count': 1}},\n",
       " (10, 11, 11, 6, 5): {'attack': {'sum_wins': 1, 'count': 1}},\n",
       " (5, 6, 5, 4, 13): {'swap': {'sum_wins': 0, 'count': 1}},\n",
       " (6, 6, 5, 6, 6): {'swap': {'sum_wins': 0, 'count': 1}},\n",
       " (6, 8, 6, 5, 10): {'attack': {'sum_wins': 1, 'count': 1}},\n",
       " (5, 6, 5, 8, 6): {'attack': {'sum_wins': 1, 'count': 1}},\n",
       " (5, 6, 5, 8, 9): {'swap': {'sum_wins': 0, 'count': 1}},\n",
       " (8, 6, 5, 9, 11): {'attack': {'sum_wins': 1, 'count': 1}},\n",
       " (12, 5, 12, 4, 9): {'swap': {'sum_wins': 0, 'count': 1}},\n",
       " (10, 5, 8, 6, 4): {'attack': {'sum_wins': 1, 'count': 1}},\n",
       " (11, 5, 11, 6, 10): {'swap': {'sum_wins': 1, 'count': 1}},\n",
       " (8, 6, 8, 7, 5): {'swap': {'sum_wins': 1, 'count': 1}},\n",
       " (5, 6, 5, 13, 5): {'attack': {'sum_wins': 1, 'count': 1}},\n",
       " (8, 8, 8, 5, 3): {'swap': {'sum_wins': 1, 'count': 1}},\n",
       " (6, 11, 6, 6, 8): {'attack': {'sum_wins': 0, 'count': 1}},\n",
       " (5, 8, 5, 8, 13): {'swap': {'sum_wins': 0, 'count': 1}},\n",
       " (8, 6, 8, 6, 4): {'attack': {'sum_wins': 1, 'count': 1}},\n",
       " (6, 6, 8, 12, 9): {'attack': {'sum_wins': 1, 'count': 1}},\n",
       " (8, 11, 6, 13, 6): {'swap': {'sum_wins': 0, 'count': 1}},\n",
       " (8, 6, 9, 5, 4): {'swap': {'sum_wins': 0, 'count': 1}},\n",
       " (9, 5, 8, 9, 13): {'swap': {'sum_wins': 0, 'count': 1}},\n",
       " (5, 13, 6, 8, 1): {'swap': {'sum_wins': 0, 'count': 1}},\n",
       " (11, 5, 5, 3, 6): {'swap': {'sum_wins': 1, 'count': 1}},\n",
       " (5, 5, 8, 11, 3): {'swap': {'sum_wins': 0, 'count': 1}},\n",
       " (5, 5, 6, 5, 13): {'attack': {'sum_wins': 1, 'count': 1}},\n",
       " (8, 8, 9, 7, 5): {'attack': {'sum_wins': 1, 'count': 1}},\n",
       " (5, 8, 6, 13, 4): {'swap': {'sum_wins': 0, 'count': 1}},\n",
       " (8, 11, 5, 12, 6): {'swap': {'sum_wins': 1, 'count': 1}},\n",
       " (8, 6, 8, 12, 13): {'swap': {'sum_wins': 0, 'count': 1}},\n",
       " (13, 8, 6, 4, 7): {'attack': {'sum_wins': 1, 'count': 1}},\n",
       " (5, 8, 8, 10, 10): {'swap': {'sum_wins': 0, 'count': 1}},\n",
       " (5, 5, 6, 5, 5): {'attack': {'sum_wins': 0, 'count': 1}},\n",
       " (5, 8, 11, 8, 5): {'swap': {'sum_wins': 0, 'count': 1}},\n",
       " (13, 5, 8, 3, 11): {'attack': {'sum_wins': 1, 'count': 1}},\n",
       " (8, 6, 6, 6, 7): {'attack': {'sum_wins': 1, 'count': 1},\n",
       "  'swap': {'sum_wins': 0, 'count': 1}},\n",
       " (6, 6, 10, 8, 6): {'attack': {'sum_wins': 0, 'count': 1}},\n",
       " (9, 5, 8, 4, 4): {'attack': {'sum_wins': 1, 'count': 1}},\n",
       " (8, 6, 5, 8, 8): {'attack': {'sum_wins': 1, 'count': 1}},\n",
       " (6, 8, 6, 13, 8): {'attack': {'sum_wins': 1, 'count': 1}},\n",
       " (6, 5, 11, 8, 12): {'swap': {'sum_wins': 1, 'count': 1}},\n",
       " (6, 6, 5, 5, 10): {'swap': {'sum_wins': 0, 'count': 1}},\n",
       " (6, 9, 6, 12, 2): {'attack': {'sum_wins': 1, 'count': 1}},\n",
       " (10, 6, 8, 4, 8): {'swap': {'sum_wins': 0, 'count': 1}},\n",
       " (8, 5, 5, 9, 10): {'swap': {'sum_wins': 0, 'count': 1}},\n",
       " (6, 8, 5, 7, 5): {'attack': {'sum_wins': 0, 'count': 1}},\n",
       " (5, 8, 8, 8, 3): {'attack': {'sum_wins': 0, 'count': 1}},\n",
       " (9, 6, 6, 6, 8): {'attack': {'sum_wins': 0, 'count': 1}},\n",
       " (6, 5, 5, 5, 8): {'swap': {'sum_wins': 1, 'count': 1}},\n",
       " (5, 5, 6, 9, 5): {'swap': {'sum_wins': 0, 'count': 1}},\n",
       " (8, 8, 6, 6, 6): {'swap': {'sum_wins': 1, 'count': 1}},\n",
       " (5, 5, 11, 12, 7): {'attack': {'sum_wins': 1, 'count': 1}},\n",
       " (5, 8, 8, 8, 6): {'swap': {'sum_wins': 0, 'count': 1}},\n",
       " (6, 6, 8, 6, 5): {'swap': {'sum_wins': 0, 'count': 1}},\n",
       " (8, 8, 5, 12, 8): {'attack': {'sum_wins': 1, 'count': 1}},\n",
       " (6, 10, 5, 12, 3): {'attack': {'sum_wins': 1, 'count': 1}},\n",
       " (6, 12, 6, 8, 3): {'attack': {'sum_wins': 1, 'count': 1}},\n",
       " (10, 6, 10, 4, 9): {'swap': {'sum_wins': 1, 'count': 1}},\n",
       " (8, 5, 6, 9, 7): {'swap': {'sum_wins': 0, 'count': 1}},\n",
       " (6, 8, 5, 5, 5): {'swap': {'sum_wins': 0, 'count': 1}},\n",
       " (5, 8, 9, 13, 4): {'attack': {'sum_wins': 1, 'count': 1}},\n",
       " (5, 5, 8, 7, 4): {'attack': {'sum_wins': 1, 'count': 1}},\n",
       " (8, 5, 5, 4, 8): {'swap': {'sum_wins': 0, 'count': 1}},\n",
       " (5, 5, 5, 4, 13): {'attack': {'sum_wins': 1, 'count': 1}},\n",
       " (5, 8, 5, 4, 8): {'swap': {'sum_wins': 0, 'count': 1}},\n",
       " (5, 5, 8, 8, 5): {'swap': {'sum_wins': 0, 'count': 1}},\n",
       " (6, 6, 5, 5, 9): {'attack': {'sum_wins': 1, 'count': 1}},\n",
       " (9, 6, 6, 7, 7): {'attack': {'sum_wins': 1, 'count': 1}},\n",
       " (6, 8, 11, 4, 5): {'swap': {'sum_wins': 0, 'count': 1}},\n",
       " (6, 9, 5, 8, 13): {'swap': {'sum_wins': 0, 'count': 1}},\n",
       " (9, 8, 5, 6, 7): {'attack': {'sum_wins': 1, 'count': 1}},\n",
       " (8, 11, 8, 7, 5): {'attack': {'sum_wins': 0, 'count': 1}},\n",
       " (6, 9, 6, 9, 4): {'attack': {'sum_wins': 1, 'count': 1}},\n",
       " (8, 6, 6, 8, 5): {'swap': {'sum_wins': 0, 'count': 1}},\n",
       " (8, 5, 5, 12, 9): {'swap': {'sum_wins': 1, 'count': 1}},\n",
       " (6, 11, 5, 6, 4): {'attack': {'sum_wins': 1, 'count': 1}},\n",
       " (5, 10, 8, 7, 4): {'swap': {'sum_wins': 0, 'count': 1}},\n",
       " (8, 6, 8, 6, 9): {'attack': {'sum_wins': 1, 'count': 1}},\n",
       " (12, 8, 12, 2, 8): {'attack': {'sum_wins': 0, 'count': 1}},\n",
       " (8, 8, 11, 3, 5): {'swap': {'sum_wins': 0, 'count': 1}},\n",
       " (10, 10, 5, 9, 9): {'attack': {'sum_wins': 0, 'count': 1}},\n",
       " (5, 9, 8, 12, 5): {'attack': {'sum_wins': 0, 'count': 1}},\n",
       " (5, 10, 9, 8, 2): {'attack': {'sum_wins': 1, 'count': 1}},\n",
       " (8, 13, 5, 7, 4): {'attack': {'sum_wins': 0, 'count': 1}},\n",
       " (8, 6, 11, 6, 8): {'swap': {'sum_wins': 0, 'count': 1}},\n",
       " (10, 8, 6, 4, 4): {'attack': {'sum_wins': 0, 'count': 1}},\n",
       " (8, 5, 8, 9, 7): {'swap': {'sum_wins': 0, 'count': 1}},\n",
       " (5, 8, 6, 9, 5): {'swap': {'sum_wins': 0, 'count': 1}}}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# action_state_results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({8}, {10})"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eval Agents Loop\n",
    "* based on two agents and results, see how statistically signficant the difference is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to run 0.038 minutes\n",
      "Time to run 0.005 seconds per battle\n",
      "Time to run 1.281 hours per million battles\n",
      "{0: 236, 1: 264, -1: 0}\n",
      "{0: {3: 311, 1: 316, 0: 510, 2: 314}, 1: {0: 528, 3: 302, 1: 324, 2: 297}}\n"
     ]
    }
   ],
   "source": [
    "num_battles = 10\n",
    "\n",
    "winner_dict = {\n",
    "    0:0,\n",
    "    1:0,\n",
    "    -1:0\n",
    "}\n",
    "\n",
    "pkm_env_action_dict = {\n",
    "    0:{},\n",
    "    1:{},\n",
    "}\n",
    "\n",
    "action_lookup_dict = copy.deepcopy(action_state_results_dict)\n",
    "\n",
    "max_episode_steps = 250\n",
    "agent_index = 0\n",
    "\n",
    "lookup_dict = make_lookup_dict()\n",
    "team_generator = RandomTeamGenerator(2)\n",
    "\n",
    "time_int = int(time.time())\n",
    "save_tag =  f\"_smoke_test_winner_dict_{time_int}\"\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "for battle_idx in range(num_battles):\n",
    "    \n",
    "    agent_team = team_generator.get_team().get_battle_team([0, 1, ])\n",
    "    opp_team = team_generator.get_team().get_battle_team([0, 1, ])\n",
    "\n",
    "    # set new environment with teams\n",
    "    env = PkmBattleEnv((agent_team, opp_team),\n",
    "                   encode=(False, False)) \n",
    " \n",
    "    game_state, info = env.reset()\n",
    "\n",
    "    # is_first_move = True\n",
    "    # agent_first_move = None\n",
    "    state_key = None\n",
    "\n",
    "    for episode_step in range(max_episode_steps):\n",
    "\n",
    "        agent_pre_env_action = 0\n",
    "        agent_env_action, agent_team_best_damage_list = turn_agent_action_into_env_action(agent_pre_env_action, game_state[0])\n",
    "        opp_action, opp_best_damage_list = get_best_active_damage_action(game_state[1])\n",
    "\n",
    "        if opp_action < 0 or opp_action > 3:\n",
    "            print(\"Error opp action is not 0 to 3\")\n",
    "        elif len(opp_best_damage_list) == 0:\n",
    "            print(\"Error opp best damage list is empty\")\n",
    "        elif opp_best_damage_list[0] < 0:\n",
    "            print(\"Error opp best damage is negative\")\n",
    "            \n",
    "        if state_key is None:\n",
    "            # for now just doing part dmg to opp\n",
    "            #dmg_array = np.array(agent_best_damage_list + [opp_best_damage,])\n",
    "            dmg_array = np.array(agent_team_best_damage_list)\n",
    "            state_key = turn_game_state_into_dict_key(game_state[0], game_state[1], lookup_dict, dmg_array)\n",
    "\n",
    "            # for now only override the initial action, could change this to possibly swap later as well\n",
    "            if state_key in action_lookup_dict:\n",
    "                agent_env_action = max(action_lookup_dict[state_key], key=action_lookup_dict[state_key].get)\n",
    "\n",
    "\n",
    "        if agent_pre_env_action == 1 and agent_env_action != 4:\n",
    "            print(\"Error agent action is 1 but env action is not 4 \")\n",
    "        elif agent_pre_env_action == 0:\n",
    "            if (agent_env_action < 0 or agent_env_action > 3):\n",
    "                print(\"Error agent action is 0 but env action is not 0 to 3 \")\n",
    "            elif len(agent_team_best_damage_list) == 0:\n",
    "                print(\"Error agent action is 0 but best damage list is empty\")\n",
    "            elif agent_team_best_damage_list[0] < 0:\n",
    "                print(\"Error agent action is 0 but best damage is negative\")\n",
    "\n",
    "        \n",
    "   \n",
    "        # enter action and step the env\n",
    "        action_list = [agent_env_action, opp_action]\n",
    "\n",
    "        pkm_env_action_dict = add_action_to_pkm_env_action_dict(agent_env_action, pkm_env_action_dict, 0)\n",
    "        pkm_env_action_dict = add_action_to_pkm_env_action_dict(opp_action, pkm_env_action_dict, 1)\n",
    "\n",
    "        #print(action_list)\n",
    "        game_state, _not_used_reward, terminated, truncated, info = env.step(action_list)  # for inference, we don't need reward\n",
    "\n",
    "        if episode_step == max_episode_steps - 1:\n",
    "            print('Warning: max steps reached')\n",
    "            terminated = True\n",
    "\n",
    "        if terminated:\n",
    "            winner = env.winner\n",
    "            if winner == agent_index:\n",
    "                win_int = 1\n",
    "            else:\n",
    "                win_int = 0\n",
    "\n",
    "            if winner in winner_dict:\n",
    "                winner_dict[winner] += 1\n",
    "\n",
    "            break\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Time to run {(end_time - start_time) / 60:.3f} minutes\")\n",
    "print(f\"Time to run {(end_time - start_time) / num_battles:.3f} seconds per battle\")\n",
    "print(f\"Time to run {((end_time - start_time) / num_battles / 60 / 60) * 1000000:.3f} hours per million battles\")\n",
    "\n",
    "print(winner_dict)\n",
    "print(pkm_env_action_dict)\n",
    "\n",
    "save_object_as_pkl(winner_dict, 'eval_winner_dict_smoke_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See if results significant\n",
    "* should probably do this with ELO?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player 1 Win rate: 0.472\n",
      "Chi-square statistic: 2.916\n",
      "P-value: 0.08771\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "def chi_square_test(win_loss_draw1, win_loss_draw2):\n",
    "    \"\"\"\n",
    "    Performs a Chi-square test on two entities with win, loss, and draw counts.\n",
    "    \n",
    "    Parameters:\n",
    "    - win_loss_draw1: A list or tuple of win, loss, and draw counts for entity 1 (e.g., [wins, losses, draws]).\n",
    "    - win_loss_draw2: A list or tuple of win, loss, and draw counts for entity 2.\n",
    "    \n",
    "    Returns:\n",
    "    - Chi-square statistic, p-value, and interpretation as a string.\n",
    "    \"\"\"\n",
    "    # Create a contingency table\n",
    "    contingency_table = [win_loss_draw1, win_loss_draw2]\n",
    "    \n",
    "    # Perform the Chi-square test\n",
    "    chi2, pval, dof, expected = chi2_contingency(contingency_table)\n",
    "    \n",
    "    # Interpret the results\n",
    "    interpretation = (\"There is a statistically significant difference in outcomes between the two entities.\"\n",
    "                      if pval < 0.05 else\n",
    "                      \"There is no statistically significant difference in outcomes between the two entities.\")\n",
    "    \n",
    "    print(f'Player 1 Win rate: { win_loss_draw1[0] / sum(win_loss_draw1):.3f}')\n",
    "\n",
    "\n",
    "    print(f'Chi-square statistic: {chi2:.3f}')\n",
    "    print(f'P-value: {pval:.5f}')\n",
    "\n",
    "    return chi2, pval, interpretation\n",
    "\n",
    "# # Example usage\n",
    "#chi2, pval, interpretation = chi_square_test([120, 80, 50], [130, 70, 60])\n",
    "\n",
    "chi2, pval, interpretation = chi_square_test([winner_dict[0],\n",
    "                                              winner_dict[1],\n",
    "                                              #winner_dict[-1]\n",
    "                                              ],\n",
    "                                             [winner_dict[1],\n",
    "                                              winner_dict[0],\n",
    "                                              #winner_dict[-1]\n",
    "                                              ],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- x is  150\n",
      "Player 1 Win rate: 0.500\n",
      "Chi-square statistic: 0.000\n",
      "P-value: 1.00000\n",
      "________\n",
      "--- x is  155\n",
      "Player 1 Win rate: 0.517\n",
      "Chi-square statistic: 0.540\n",
      "P-value: 0.46243\n",
      "________\n",
      "--- x is  160\n",
      "Player 1 Win rate: 0.533\n",
      "Chi-square statistic: 2.407\n",
      "P-value: 0.12082\n",
      "________\n",
      "--- x is  165\n",
      "Player 1 Win rate: 0.550\n",
      "Chi-square statistic: 5.607\n",
      "P-value: 0.01789\n",
      "________\n",
      "--- x is  170\n",
      "Player 1 Win rate: 0.567\n",
      "Chi-square statistic: 10.140\n",
      "P-value: 0.00145\n",
      "________\n",
      "--- x is  175\n",
      "Player 1 Win rate: 0.583\n",
      "Chi-square statistic: 16.007\n",
      "P-value: 0.00006\n",
      "________\n",
      "--- x is  180\n",
      "Player 1 Win rate: 0.600\n",
      "Chi-square statistic: 23.207\n",
      "P-value: 0.00000\n",
      "________\n",
      "--- x is  185\n",
      "Player 1 Win rate: 0.617\n",
      "Chi-square statistic: 31.740\n",
      "P-value: 0.00000\n",
      "________\n",
      "--- x is  190\n",
      "Player 1 Win rate: 0.633\n",
      "Chi-square statistic: 41.607\n",
      "P-value: 0.00000\n",
      "________\n",
      "--- x is  195\n",
      "Player 1 Win rate: 0.650\n",
      "Chi-square statistic: 52.807\n",
      "P-value: 0.00000\n",
      "________\n"
     ]
    }
   ],
   "source": [
    "# test where it is significant\n",
    "\n",
    "for x in range(150, 200, 5):\n",
    "    winner_dict = {\n",
    "        0:x,\n",
    "        1:300-x,\n",
    "        -1:0\n",
    "    }\n",
    "    print(\"--- x is \", x)\n",
    "    chi2, pval, interpretation = chi_square_test([winner_dict[0],\n",
    "                                                winner_dict[1],\n",
    "                                                #winner_dict[-1]\n",
    "                                                ],\n",
    "                                                [winner_dict[1],\n",
    "                                                winner_dict[0],\n",
    "                                                #winner_dict[-1]\n",
    "                                                ],)\n",
    "    print(\"________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rates: 0.540 vs. 0.460\n",
      "T-statistic: 1.96261\n",
      "P-value: 0.05015\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "\n",
    "def compare_rates(successes_group1, observations_group1, successes_group2, observations_group2):\n",
    "    \"\"\"\n",
    "    Compares two observed rates using a two-sample t-test and prints the t-statistic and p-value.\n",
    "    \n",
    "    Parameters:\n",
    "    - successes_group1: Number of successes in group 1\n",
    "    - observations_group1: Number of observations in group 1\n",
    "    - successes_group2: Number of successes in group 2\n",
    "    - observations_group2: Number of observations in group 2\n",
    "    \"\"\"\n",
    "    # Calculate rates\n",
    "    rate_group1 = successes_group1 / observations_group1\n",
    "    rate_group2 = successes_group2 / observations_group2\n",
    "\n",
    "    # Convert rates to \"success\" arrays\n",
    "    data_group1 = np.array([1] * successes_group1 + [0] * (observations_group1 - successes_group1))\n",
    "    data_group2 = np.array([1] * successes_group2 + [0] * (observations_group2 - successes_group2))\n",
    "\n",
    "    # Perform the two-sample t-test\n",
    "    stat, pval = ttest_ind(data_group1, data_group2)\n",
    "\n",
    "    # Print rounded t-statistic and p-value\n",
    "    print(\"Rates: {:.3f} vs. {:.3f}\".format(rate_group1, rate_group2))\n",
    "    print(f'T-statistic: {stat:.5f}')\n",
    "    print(f'P-value: {pval:.5f}')\n",
    "\n",
    "# Example usage\n",
    "#compare_rates(45, 100, 50, 120)\n",
    "\n",
    "compare_rates(winner_dict[0], num_battles, winner_dict[1], num_battles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "Rates: 0.500 vs. 0.500\n",
      "T-statistic: 0.00000\n",
      "P-value: 1.00000\n",
      "160\n",
      "Rates: 0.533 vs. 0.467\n",
      "T-statistic: 1.63390\n",
      "P-value: 0.10281\n",
      "170\n",
      "Rates: 0.567 vs. 0.433\n",
      "T-statistic: 3.28991\n",
      "P-value: 0.00106\n",
      "175\n",
      "Rates: 0.583 vs. 0.417\n",
      "T-statistic: 4.13349\n",
      "P-value: 0.00004\n",
      "200\n",
      "Rates: 0.667 vs. 0.333\n",
      "T-statistic: 8.64581\n",
      "P-value: 0.00000\n",
      "225\n",
      "Rates: 0.750 vs. 0.250\n",
      "T-statistic: 14.11855\n",
      "P-value: 0.00000\n",
      "250\n",
      "Rates: 0.833 vs. 0.167\n",
      "T-statistic: 21.87236\n",
      "P-value: 0.00000\n",
      "275\n",
      "Rates: 0.917 vs. 0.083\n",
      "T-statistic: 36.86585\n",
      "P-value: 0.00000\n"
     ]
    }
   ],
   "source": [
    "for test_wins in [150, 160, 170, 175, 200, 225, 250, 275]:\n",
    "    print(test_wins)\n",
    "    compare_rates(test_wins, num_battles, num_battles-test_wins, num_battles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(episode_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((<vgc.engine.PkmBattleEnv.PkmBattleEnv at 0x17e31fafac0>,\n",
       "  <vgc.engine.PkmBattleEnv.PkmBattleEnv at 0x17e31fa12e0>),\n",
       " [1.0, 1.0],\n",
       " True,\n",
       " False,\n",
       " {})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(action_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73.88888888888889"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".266 / 60 * 1000000 /60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
