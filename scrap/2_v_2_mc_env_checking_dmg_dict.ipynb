{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "\n",
    "from vgc.datatypes.Objects import PkmTeam, Pkm, GameState, Weather\n",
    "from vgc.engine.PkmBattleEnv import PkmBattleEnv\n",
    "from vgc.util.generator.PkmTeamGenerators import RandomTeamGenerator\n",
    "\n",
    "from vgc.datatypes.Constants import TYPE_CHART_MULTIPLIER, MAX_HIT_POINTS, MOVE_MAX_PP, DEFAULT_TEAM_SIZE\n",
    "from vgc.datatypes.Objects import PkmMove, Pkm, PkmTeam, GameState, Weather\n",
    "from vgc.datatypes.Types import PkmStat, PkmType, WeatherCondition, \\\n",
    "    N_TYPES, N_STATUS, N_STATS, N_ENTRY_HAZARD, N_WEATHER, PkmStatus, PkmEntryHazard\n",
    "\n",
    "import math\n",
    "import pprint\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirm dmg estimate matches reality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nreviewed code, looks teh same\\n\\n\\thttps://gitlab.com/DracoStriker/pokemon-vgc-engine/-/blob/master/vgc/engine/PkmBattleEnv.py?ref_type=heads#L489\\n\\n\\tfixed_damage = self.__get_fixed_damage()\\n        if fixed_damage > 0. and TYPE_CHART_MULTIPLIER[move.type][opp_pkm.type] > 0.:\\n            damage = fixed_damage\\n        else:\\n            stab = 1.5 if move.type == pkm.type else 1.\\n            if (move.type == PkmType.WATER and self.weather.condition == WeatherCondition.RAIN) or (\\n                    move.type == PkmType.FIRE and self.weather.condition == WeatherCondition.SUNNY):\\n                weather = 1.5\\n            elif (move.type == PkmType.WATER and self.weather.condition == WeatherCondition.SUNNY) or (\\n                    move.type == PkmType.FIRE and self.weather.condition == WeatherCondition.RAIN):\\n                weather = .5\\n            else:\\n                weather = 1.\\n            stage_level = team.stage[PkmStat.ATTACK] - opp_team.stage[PkmStat.DEFENSE]\\n            stage = (stage_level + 2.) / 2 if stage_level >= 0. else 2. / (np.abs(stage_level) + 2.)\\n            multiplier = TYPE_CHART_MULTIPLIER[move.type][opp_pkm.type] if move != Struggle else 1.0\\n            damage = multiplier * stab * weather * stage * move.power\\n\\n    def __get_fixed_damage(self) -> float:\\n        damage = self.move_view.damage\\n        self.move_view._damage = 0.\\n        return damage\\n\\n    missing the struggle part\\n\\nCode testing\\n    add debug to estiamte dmg part\\n    after found a difference see what is happening in the code\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "reviewed code, looks teh same\n",
    "\n",
    "\thttps://gitlab.com/DracoStriker/pokemon-vgc-engine/-/blob/master/vgc/engine/PkmBattleEnv.py?ref_type=heads#L489\n",
    "\n",
    "\tfixed_damage = self.__get_fixed_damage()\n",
    "        if fixed_damage > 0. and TYPE_CHART_MULTIPLIER[move.type][opp_pkm.type] > 0.:\n",
    "            damage = fixed_damage\n",
    "        else:\n",
    "            stab = 1.5 if move.type == pkm.type else 1.\n",
    "            if (move.type == PkmType.WATER and self.weather.condition == WeatherCondition.RAIN) or (\n",
    "                    move.type == PkmType.FIRE and self.weather.condition == WeatherCondition.SUNNY):\n",
    "                weather = 1.5\n",
    "            elif (move.type == PkmType.WATER and self.weather.condition == WeatherCondition.SUNNY) or (\n",
    "                    move.type == PkmType.FIRE and self.weather.condition == WeatherCondition.RAIN):\n",
    "                weather = .5\n",
    "            else:\n",
    "                weather = 1.\n",
    "            stage_level = team.stage[PkmStat.ATTACK] - opp_team.stage[PkmStat.DEFENSE]\n",
    "            stage = (stage_level + 2.) / 2 if stage_level >= 0. else 2. / (np.abs(stage_level) + 2.)\n",
    "            multiplier = TYPE_CHART_MULTIPLIER[move.type][opp_pkm.type] if move != Struggle else 1.0\n",
    "            damage = multiplier * stab * weather * stage * move.power\n",
    "\n",
    "    def __get_fixed_damage(self) -> float:\n",
    "        damage = self.move_view.damage\n",
    "        self.move_view._damage = 0.\n",
    "        return damage\n",
    "\n",
    "    missing the struggle part\n",
    "\n",
    "Code testing\n",
    "    add debug to estiamte dmg part\n",
    "    after found a difference see what is happening in the code\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_damage(move_type: PkmType, pkm_type: PkmType, move_power: float, opp_pkm_type: PkmType,\n",
    "                    attack_stage: int, defense_stage: int, weather: WeatherCondition) -> float:\n",
    "    '''\n",
    "    from the repo\n",
    "    '''\n",
    "    stab = 1.5 if move_type == pkm_type else 1.\n",
    "    if (move_type == PkmType.WATER and weather == WeatherCondition.RAIN) or (\n",
    "            move_type == PkmType.FIRE and weather == WeatherCondition.SUNNY):\n",
    "        weather = 1.5\n",
    "    elif (move_type == PkmType.WATER and weather == WeatherCondition.SUNNY) or (\n",
    "            move_type == PkmType.FIRE and weather == WeatherCondition.RAIN):\n",
    "        weather = .5\n",
    "    else:\n",
    "        weather = 1.\n",
    "    stage_level = attack_stage - defense_stage\n",
    "    stage = (stage_level + 2.) / 2 if stage_level >= 0. else 2. / (np.abs(stage_level) + 2.)\n",
    "    damage = TYPE_CHART_MULTIPLIER[move_type][opp_pkm_type] * stab * weather * stage * move_power\n",
    "\n",
    "    #if is_debug:\n",
    "    multiplier = TYPE_CHART_MULTIPLIER[move_type][opp_pkm_type]\n",
    "    debug_string = f'stab: {stab}, weather: {weather}, stage: {stage}, damage: {damage}, multiplier: {multiplier}, '\\\n",
    "        f'move_type {move_type}, move_power: {move_power}, opp_pkm_type: {opp_pkm_type}, '\n",
    "\n",
    "    #print(damage, move_type, pkm_type, move_power, opp_pkm_type, attack_stage, defense_stage, weather)\n",
    "    return damage, debug_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### step through env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_generator = RandomTeamGenerator(2)\n",
    "\n",
    "for i in range(10000):\n",
    "    agent_team = team_generator.get_team().get_battle_team([0, 1, 2])\n",
    "    opp_team = team_generator.get_team().get_battle_team([0, 1, 2])\n",
    "\n",
    "    test_env = PkmBattleEnv((agent_team, opp_team),\n",
    "                    encode=(False, False), debug=True)\n",
    "    state, info = test_env.reset()\n",
    "\n",
    "    # print(\"pre move\")\n",
    "    # team_0_active = state[0].teams[0].active\n",
    "    # state_0_team_1 = state[0].teams[1]\n",
    "    # active = state_0_team_1.active\n",
    "\n",
    "    # attack into a swap\n",
    "    move_int = np.random.randint(0, 4)\n",
    "    attacking_pkm = state[0].teams[0].active\n",
    "    #defending_pkm = state[1].teams[0].active\n",
    "    defending_pkm = state[1].teams[0].party[0]\n",
    "\n",
    "    move_type = attacking_pkm.moves[move_int].type\n",
    "    defending_pkm_type = defending_pkm.type\n",
    "\n",
    "    # if defending_pkm.max_hp > 240.:\n",
    "    #     continue\n",
    "\n",
    "    dmg_estimate, debug_string = estimate_damage(move_type,\n",
    "                                   attacking_pkm.type, attacking_pkm.moves[move_int].power,\n",
    "                                   defending_pkm_type , 0, 0, test_env.weather.condition)\n",
    "    \n",
    "    # estimate_damage(move_type: PkmType, pkm_type: PkmType, move_power: float, opp_pkm_type: PkmType,\n",
    "    #                 attack_stage: int, defense_stage: int, weather: WeatherCondition) -> float:\n",
    "    \n",
    "    state, _, _, _, _ = test_env.step([move_int, 4])\n",
    "\n",
    "    # see dmg taken for pkm that took damage\n",
    "    dmg_taken = 0\n",
    "    for pkm in [state[1].teams[0].active] + state[1].teams[0].party:\n",
    "        if pkm.max_hp > pkm.hp:\n",
    "            dmg_taken = pkm.max_hp - pkm.hp\n",
    "            if pkm.hp == 0:\n",
    "                is_fainted = True\n",
    "            else:\n",
    "                is_fainted = False\n",
    "            break\n",
    "\n",
    "    # dmg_taken = state[1].teams[0].active.max_hp - state[1].teams[0].active.hp\n",
    "\n",
    "    if np.abs(dmg_estimate - dmg_taken) >= 1.:\n",
    "        if not is_fainted:\n",
    "            print(\"---\")\n",
    "            print(\"Damage values not equal and pkm not fainted\")\n",
    "            print(f\"dmg_estimate: {dmg_estimate}, dmg_taken: {dmg_taken}, is_fainted: {is_fainted}, move_int: {move_int}, iter {i}\")\n",
    "            print(move_type, defending_pkm_type)\n",
    "            #print(debug_string)\n",
    "            #print(\"multiplier\", TYPE_CHART_MULTIPLIER[move_type][defending_pkm_type])\n",
    "            # print(\"move_type\", move_type)\n",
    "            # print(\"defending pkm type\", defending_pkm_type)\n",
    "            print(\"________\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('TURN 1\\n'\n",
      " '\\n'\n",
      " 'MOVE: Trainer 1 with Pkm(Type=DRAGON, HP=228, Moves={PkmMove(Power=66, '\n",
      " 'Acc=1.0, PP=10, Type=DRAGON), PkmMove(Power=174, Acc=1.0, PP=9, Type=DARK), '\n",
      " 'PkmMove(Power=30, Acc=1.0, PP=10, Type=STEEL), PkmMove(Power=102, Acc=1.0, '\n",
      " 'PP=10, Type=STEEL), }) uses PkmMove(Power=174, Acc=1.0, PP=9, Type=DARK)\\n'\n",
      " 'DAMAGE: deals 120.0 damage, hp reduces from 120.0 to 0.0 for Pkm(Type=ROCK, '\n",
      " 'HP=0, Moves={PkmMove(Power=174, Acc=1.0, PP=10, Type=ROCK), '\n",
      " 'PkmMove(Power=30, Acc=1.0, PP=10, Type=GROUND), PkmMove(Power=246, Acc=1.0, '\n",
      " 'PP=10, Type=STEEL), PkmMove(Power=30, Acc=1.0, PP=10, Type=ICE), })\\n'\n",
      " 'CANNOT MOVE: Trainer 0 cannot move\\n'\n",
      " 'FAINTED: Pkm(Type=ROCK, HP=0, Moves={PkmMove(Power=174, Acc=1.0, PP=10, '\n",
      " 'Type=ROCK), PkmMove(Power=30, Acc=1.0, PP=10, Type=GROUND), '\n",
      " 'PkmMove(Power=246, Acc=1.0, PP=10, Type=STEEL), PkmMove(Power=30, Acc=1.0, '\n",
      " 'PP=10, Type=ICE), })\\n')\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(test_env.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PkmType.DRAGON 228.0 228.0\n",
      "PkmType.DARK 120.0 120.0\n",
      "PkmType.WATER 120.0 120.0\n"
     ]
    }
   ],
   "source": [
    "for pkm in [state[1].teams[0].active] + state[1].teams[0].party:\n",
    "    print(pkm.type, pkm.hp, pkm.max_hp, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PkmType.FAIRY 264.0 264.0\n",
      "PkmType.DARK 120.0 120.0\n",
      "PkmType.WATER 120.0 120.0\n"
     ]
    }
   ],
   "source": [
    "for pkm in [state[0].teams[0].active] + state[1].teams[0].party:\n",
    "    print(pkm.type, pkm.hp, pkm.max_hp, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PkmType.FAIRY 120.0 120.0\n",
      "PkmType.ROCK 192.0 192.0\n",
      "PkmType.ICE 120.0 120.0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PkmType.GROUND 138.0\n"
     ]
    }
   ],
   "source": [
    "print(state[0].teams[0].active.moves[move_int].type, state[0].teams[0].active.moves[move_int].power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PkmType.FLYING 156.0 156.0\n",
      "PkmType.GHOST 120.0 120.0\n",
      "PkmType.DRAGON 156.0 156.0\n"
     ]
    }
   ],
   "source": [
    "for pkm in [state[1].teams[0].active] + state[1].teams[0].party:\n",
    "    print(pkm.type, pkm.max_hp, pkm.hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PkmType.DRAGON 156.0 156.0\n"
     ]
    }
   ],
   "source": [
    "print(pkm.type, pkm.max_hp, pkm.hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "move_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dmg_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state[1].teams[0].active.hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state[1].teams[0].active.max_hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a dmg to and from dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_turns_to_faint_list(team_1_game_state, team_2_game_state, max_turns_to_faint_value):\n",
    "    '''\n",
    "    put in zero for the fainted\n",
    "        handle the check for fainted in HP\n",
    "    assume everything is revealed\n",
    "        handle masking elsewhere\n",
    "    '''\n",
    "\n",
    "    # Get weather condition\n",
    "    weather = team_1_game_state.weather.condition\n",
    "\n",
    "    # Get my Pokémon team\n",
    "    team_1 = team_1_game_state.teams[0]\n",
    "    team_1_pkm_list = [team_1.active] + team_1.party\n",
    "\n",
    "    # Get opponent's team\n",
    "    team_2 = team_2_game_state.teams[0]\n",
    "    team_2_pkm_list = [team_2.active] + team_2.party\n",
    "\n",
    "    # Iterate over all my Pokémon and their moves to find the most damaging move\n",
    "    best_damage_list = []\n",
    "    turns_to_faint_list = []\n",
    "    hp_list = []\n",
    "\n",
    "    for team_1_pkm_index, team_1_pkm in enumerate(team_1_pkm_list):\n",
    "        \n",
    "\n",
    "        for team_2_pkm_index, team_2_pkm in enumerate(team_2_pkm_list):\n",
    "            # Initialize variables for the best move and its damage\n",
    "            best_damage = -np.inf\n",
    "\n",
    "            if team_1_pkm_index == 0:\n",
    "                team_1_attack_stage = team_1.stage[PkmStat.ATTACK]\n",
    "            else:\n",
    "                team_1_attack_stage = 0\n",
    "            \n",
    "            if team_2_pkm_index == 0:\n",
    "                team_2_defense_stage = team_2.stage[PkmStat.DEFENSE]\n",
    "            else:\n",
    "                team_2_defense_stage = 0\n",
    "\n",
    "            for move_index, move in enumerate(team_1_pkm.moves):\n",
    "                \n",
    "                damage = estimate_damage(move.type, team_1_pkm.type, move.power, team_2_pkm.type, team_1_attack_stage,\n",
    "                                            team_2_defense_stage, weather)\n",
    "\n",
    "                # Check if the current move has higher damage than the previous best move\n",
    "                if damage > best_damage:\n",
    "                    best_damage = damage\n",
    "\n",
    "            # get best dmg for each pokemon\n",
    "            best_damage_list.append(best_damage)\n",
    "            hp_list.append(team_2_pkm.hp)\n",
    "\n",
    "            if best_damage > 0.:\n",
    "                turns_to_faint = math.ceil(team_2_pkm.hp / best_damage)\n",
    "            else:\n",
    "                turns_to_faint = max_turns_to_faint_value\n",
    "\n",
    "            turns_to_faint_list.append(turns_to_faint)\n",
    "\n",
    "    # print(turns_to_faint_list)\n",
    "    # print(best_damage_list)\n",
    "    # print(hp_list)\n",
    "\n",
    "    return turns_to_faint_list\n",
    "\n",
    "\n",
    "def estimate_damage(move_type: PkmType, pkm_type: PkmType, move_power: float, opp_pkm_type: PkmType,\n",
    "                    attack_stage: int, defense_stage: int, weather: WeatherCondition) -> float:\n",
    "        '''\n",
    "        from updated repo\n",
    "        '''\n",
    "        stab = 1.5 if move_type == pkm_type else 1.\n",
    "        if (move_type == PkmType.WATER and weather == WeatherCondition.RAIN) or (\n",
    "                move_type == PkmType.FIRE and weather == WeatherCondition.SUNNY):\n",
    "            weather = 1.5\n",
    "        elif (move_type == PkmType.WATER and weather == WeatherCondition.SUNNY) or (\n",
    "                move_type == PkmType.FIRE and weather == WeatherCondition.RAIN):\n",
    "            weather = .5\n",
    "        else:\n",
    "            weather = 1.\n",
    "        stage_level = attack_stage - defense_stage\n",
    "        stage = (stage_level + 2.) / 2 if stage_level >= 0. else 2. / (np.abs(stage_level) + 2.)\n",
    "        damage = TYPE_CHART_MULTIPLIER[move_type][opp_pkm_type] * stab * weather * stage * move_power\n",
    "\n",
    "        #print(damage, move_type, pkm_type, move_power, opp_pkm_type, attack_stage, defense_stage, weather)\n",
    "        return damage\n",
    "\n",
    "\n",
    "def save_object_as_pkl(object_to_save, save_tag):\n",
    "    '''\n",
    "    Save object a pickle file\n",
    "    '''\n",
    "    with open(f'{save_tag}.pickle', 'wb') as handle:\n",
    "        pickle.dump(object_to_save, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iters = 5000000\n",
    "max_state_value = 100\n",
    "time_start = time.time()\n",
    "\n",
    "raw_stats_dict = {}\n",
    "turns_to_faint_dict = {}\n",
    "\n",
    "team_generator = RandomTeamGenerator(2)\n",
    "\n",
    "for i in range(test_iters):\n",
    "    agent_team = team_generator.get_team().get_battle_team([0, 1, ])\n",
    "    opp_team = team_generator.get_team().get_battle_team([0, 1, ])\n",
    "\n",
    "    env = PkmBattleEnv((agent_team, opp_team), encode=(False, False)) \n",
    "\n",
    "    game_state, info = env.reset()\n",
    "\n",
    "    team_1_faint_list = get_turns_to_faint_list(game_state[0], game_state[1], max_state_value)\n",
    "    team_2_faint_list = get_turns_to_faint_list(game_state[1], game_state[0], max_state_value)\n",
    "\n",
    "    state_tuple = tuple(team_1_faint_list + team_2_faint_list)\n",
    "\n",
    "    if state_tuple in raw_stats_dict:\n",
    "        raw_stats_dict[state_tuple] += 1\n",
    "    else:\n",
    "        raw_stats_dict[state_tuple] = 1\n",
    "\n",
    "    for turns in team_1_faint_list + team_2_faint_list:\n",
    "        if turns in turns_to_faint_dict:\n",
    "            turns_to_faint_dict[turns] += 1\n",
    "        else:\n",
    "            turns_to_faint_dict[turns] = 1\n",
    "\n",
    "time_end = time.time()\n",
    "print(f\"Time to run {time_end - time_start:.3f} seconds\")\n",
    "\n",
    "print(len(raw_stats_dict))\n",
    "print(len(turns_to_faint_dict))\n",
    "\n",
    "save_object_as_pkl(raw_stats_dict, f'turns_to_faint_state_dict_{int(time_start)}')\n",
    "save_object_as_pkl(turns_to_faint_dict, f'turns_to_faint_count_dict_{int(time_start)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so like 5-8 combined and then like 9 and over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(turns_to_faint_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint.pprint(raw_stats_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iters = 5000000\n",
    "max_state_value = 100\n",
    "time_start = time.time()\n",
    "\n",
    "raw_stats_dict = {}\n",
    "turns_to_faint_dict = {}\n",
    "\n",
    "team_generator = RandomTeamGenerator(2)\n",
    "\n",
    "for i in range(test_iters):\n",
    "    agent_team = team_generator.get_team().get_battle_team([0, 1, 2])\n",
    "    opp_team = team_generator.get_team().get_battle_team([0, 1, 2])\n",
    "\n",
    "    env = PkmBattleEnv((agent_team, opp_team), encode=(False, False)) \n",
    "\n",
    "    game_state, info = env.reset()\n",
    "\n",
    "    team_1_faint_list = get_turns_to_faint_list(game_state[0], game_state[1], max_state_value)\n",
    "    team_2_faint_list = get_turns_to_faint_list(game_state[1], game_state[0], max_state_value)\n",
    "\n",
    "    state_tuple = tuple(team_1_faint_list + team_2_faint_list)\n",
    "\n",
    "    if state_tuple in raw_stats_dict:\n",
    "        raw_stats_dict[state_tuple] += 1\n",
    "    else:\n",
    "        raw_stats_dict[state_tuple] = 1\n",
    "\n",
    "    for turns in team_1_faint_list + team_2_faint_list:\n",
    "        if turns in turns_to_faint_dict:\n",
    "            turns_to_faint_dict[turns] += 1\n",
    "        else:\n",
    "            turns_to_faint_dict[turns] = 1\n",
    "\n",
    "time_end = time.time()\n",
    "print(f\"Time to run {time_end - time_start:.3f} seconds\")\n",
    "\n",
    "print(len(raw_stats_dict))\n",
    "print(len(turns_to_faint_dict))\n",
    "\n",
    "save_object_as_pkl(raw_stats_dict, f'turns_to_faint_state_dict3v3_{int(time_start)}')\n",
    "save_object_as_pkl(turns_to_faint_dict, f'turns_to_faint_count_dict3v3_{int(time_start)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(turns_to_faint_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(raw_stats_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in raw_stats_dict.items():\n",
    "    print(v, k)\n",
    "    print(len(k))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def get_turns_to_faint_array(hp_list, best_dmg_list, max_state_value):\n",
    "#     '''\n",
    "#     hp list is indexed 0 to 3 with\n",
    "#     0 agent active\n",
    "#     1 agent party best\n",
    "#     2 opp active\n",
    "#     3 opp party best\n",
    "\n",
    "#     best_dmg_list is indexed 0 to 7\n",
    "#     0 agent active dmg to opp active\n",
    "#     1 agent active dmg to opp party best\n",
    "#     2 agent party best dmg to opp active\n",
    "#     3 agent party best dmg to opp party best\n",
    "#     4 opp active dmg to agent active\n",
    "#     5 opp active dmg to agent party best\n",
    "#     6 opp party best dmg to agent active\n",
    "#     7 opp party best dmg to agent party best\n",
    "\n",
    "#     '''\n",
    "#     turns_to_faint_array = np.ones((8, ), dtype=np.float32) * -1.\n",
    "\n",
    "#     agent_active_hp_index = 0\n",
    "#     agent_party_best_hp_index = 1\n",
    "#     opp_active_hp_index = 2\n",
    "#     opp_party_best_hp_index = 3\n",
    "\n",
    "#     agent_active_dmg_to_opp_active_index = 0\n",
    "#     agent_active_dmg_to_opp_party_best_index = 1\n",
    "#     agent_party_best_dmg_to_opp_active_index = 2\n",
    "#     agent_party_best_dmg_to_opp_party_best_index = 3\n",
    "#     opp_active_dmg_to_agent_active_index = 4\n",
    "#     opp_active_dmg_to_agent_party_best_index = 5\n",
    "#     opp_party_best_dmg_to_agent_active_index = 6\n",
    "#     opp_party_best_dmg_to_agent_party_best_index = 7\n",
    "\n",
    "#     turns_to_faint_array[0] = get_dmg_turns_to_faint(hp_list[agent_active_hp_index], \n",
    "#         best_dmg_list[agent_active_dmg_to_opp_active_index], max_state_value)\n",
    "#     turns_to_faint_array[1] = get_dmg_turns_to_faint(hp_list[agent_active_hp_index],\n",
    "#         best_dmg_list[agent_active_dmg_to_opp_party_best_index], max_state_value)\n",
    "\n",
    "#     turns_to_faint_array[2] = get_dmg_turns_to_faint(hp_list[agent_party_best_hp_index],\n",
    "#         best_dmg_list[agent_party_best_dmg_to_opp_active_index], max_state_value)\n",
    "#     turns_to_faint_array[3] = get_dmg_turns_to_faint(hp_list[agent_party_best_hp_index],\n",
    "#         best_dmg_list[agent_party_best_dmg_to_opp_party_best_index], max_state_value)\n",
    "\n",
    "#     turns_to_faint_array[4] = get_dmg_turns_to_faint(hp_list[opp_active_hp_index],\n",
    "#         best_dmg_list[opp_active_dmg_to_agent_active_index], max_state_value)\n",
    "#     turns_to_faint_array[5] = get_dmg_turns_to_faint(hp_list[opp_active_hp_index],\n",
    "#         best_dmg_list[opp_active_dmg_to_agent_party_best_index], max_state_value)\n",
    "\n",
    "#     turns_to_faint_array[6] = get_dmg_turns_to_faint(hp_list[opp_party_best_hp_index],\n",
    "#         best_dmg_list[opp_party_best_dmg_to_agent_active_index], max_state_value)\n",
    "#     turns_to_faint_array[7] = get_dmg_turns_to_faint(hp_list[opp_party_best_hp_index],\n",
    "#         best_dmg_list[opp_party_best_dmg_to_agent_party_best_index], max_state_value)\n",
    "\n",
    "    \n",
    "#     turns_to_faint_array = np.ceil(turns_to_faint_array)\n",
    "#     turns_to_faint_array = turns_to_faint_array.astype(np.int32)\n",
    "#     turns_to_faint_array = turns_to_faint_array.clip(-1, max_state_value)\n",
    "\n",
    "#     return turns_to_faint_array\n",
    "\n",
    "# turns_to_faint_array = np.ones((8, ), dtype=np.int32) * -1\n",
    "# turns_to_faint_array\n",
    "# np.ones((8, ), dtype=np.float32) \n",
    "# a = np.array([1.1, 2.0, 3, 4.00001, 5.00000, 5.99999, 7, 8])  \n",
    "# b = np.ceil(a)\n",
    "# b = b.astype(int)\n",
    "# c = tuple(b)\n",
    "# c\n",
    "# import math\n",
    "# type(math.ceil(2/1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing MC Env Learning in 2 v 2 environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "working\n",
    "    finish up the loop function\n",
    "        smoke test it\n",
    "        see if saved action dict does anything eval wise. does it even trigger?\n",
    "            are results better\n",
    "    run tests on dict action space size\n",
    "    probably want to expand functions to at least what opp dmg is to party\n",
    "    check the functions work\n",
    "\n",
    "to do important:\n",
    "    can't swap if swp is identical or will be stuck in a swap loop\n",
    "    maybe add memory saying if swapped at 2 v 2 (or other levels as well)\n",
    "\n",
    "to do improvements:\n",
    "    know the opp dmg to current team. can add those states\n",
    "        DONE YES confirm this. might be a weird trick with revealed states\n",
    "    maybe find how many states are possible with raw values\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constants and loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "\n",
    "from vgc.datatypes.Objects import PkmTeam, Pkm, GameState, Weather\n",
    "from vgc.engine.PkmBattleEnv import PkmBattleEnv\n",
    "from vgc.util.generator.PkmTeamGenerators import RandomTeamGenerator\n",
    "\n",
    "from vgc.datatypes.Constants import TYPE_CHART_MULTIPLIER, MAX_HIT_POINTS, MOVE_MAX_PP, DEFAULT_TEAM_SIZE\n",
    "from vgc.datatypes.Objects import PkmMove, Pkm, PkmTeam, GameState, Weather\n",
    "from vgc.datatypes.Types import PkmStat, PkmType, WeatherCondition, \\\n",
    "    N_TYPES, N_STATUS, N_STATS, N_ENTRY_HAZARD, N_WEATHER, PkmStatus, PkmEntryHazard\n",
    "\n",
    "\n",
    "import pprint\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "grab the value from the lookup dict and see if can be used\n",
    "\n",
    "DRY for the two loops\n",
    "\n",
    "review flow of all code\n",
    "\n",
    "reveiw and test all parts of the code\n",
    "\n",
    "can this be generalized more?\n",
    "    ie not just for the first move when eval but any move?\n",
    "    idk, probably not for now\n",
    "\n",
    "due to the variability in outcomes I think I need a ton of results to tell if swap is better or not\n",
    "    like 1000 for each state and since like 500,000 states that is 500,000,000 battles\n",
    "\n",
    "TEST need to turn the states into the dict\n",
    "    TEST want to store counts and running mean of the reward\n",
    "\n",
    "TEST set up the evaluation loop for this agent vs. the base always attack agent\n",
    "\n",
    "TEST need to test how many battles can get through in how much time\n",
    "\n",
    "TEST saving the action dict\n",
    "\n",
    "TEST need to select the initial action\n",
    "TEST need to then to attack later\n",
    "TEST need to convert the attack action into the best attack\n",
    "TEST need to convert the swap action into a swap\n",
    "TEST need to store the result of the battle\n",
    "TEST convert outcome into a rewards\n",
    "\n",
    "Later\n",
    "\n",
    "functionalize the build dict loop\n",
    "functionalize the eval\n",
    "can run the dict and eval in python files\n",
    "can parallelize the dict building\n",
    "\n",
    "maybe store all states in a list then to the dict\n",
    "    works I think as long as all actions past that point are attacks\n",
    "    could then combine that later with a swap at that point maybe?\n",
    "        idk maybe not... could be the 2nd swap and then things are necessarily clear\n",
    "            ie initial pkm has been revealed and may have taken dmg (though maybe that doesn't matter)\n",
    "\n",
    "possibly store the state dict attack action for non first actions as well\n",
    "\n",
    "            \n",
    "need to add the hiding part\n",
    "    i guess it's more like some states don't know opp dmg to current pkm and sometimes do\n",
    "\n",
    "    maybe parallelize if any of this works\n",
    "\n",
    "\n",
    "can I get the best dmg from both teams even if the pkm stuff is hidden and not revealed?\n",
    "    probably yes since passing in the team specific state\n",
    "\n",
    "can check to see how accurate the attack function is\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions for Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_agent_action_into_env_action(action, agent_game_state):\n",
    "        '''\n",
    "        Action values are\n",
    "        0: select best move\n",
    "        1: switch to first pkm\n",
    "        2: switch to second pkm\n",
    "\n",
    "        Env actions are\n",
    "        0 to 3: action of active pokm\n",
    "        4: switch to first pkm\n",
    "        5: switch to second pkm\n",
    "        '''\n",
    "        # always get best move and action dmg list\n",
    "        best_active_action, best_damage_list = get_best_active_damage_action(agent_game_state)\n",
    "\n",
    "        if action == 0:\n",
    "            # get best dmg action\n",
    "            action = best_active_action\n",
    "        else:\n",
    "            # switch to first or second pkm if alive\n",
    "            if action == 1 or action == 2:\n",
    "                pkm = agent_game_state.teams[0].party[action-1]\n",
    "                if pkm.fainted() or pkm.hp <= 0.0:\n",
    "                    action = best_active_action\n",
    "                else:\n",
    "                    action = action + 3\n",
    "            else:\n",
    "                action = best_active_action\n",
    "\n",
    "        return action, best_damage_list\n",
    "\n",
    "\n",
    "def get_best_active_damage_action(g: GameState):\n",
    "    '''\n",
    "    '''\n",
    "    # Get weather condition\n",
    "    weather = g.weather.condition\n",
    "\n",
    "    # Get my Pokémon team\n",
    "    my_team = g.teams[0]\n",
    "    my_pkms = [my_team.active] + my_team.party\n",
    "\n",
    "    # Get opponent's team\n",
    "    opp_team = g.teams[1]\n",
    "    opp_active = opp_team.active\n",
    "\n",
    "    opp_active_type = opp_active.type\n",
    "    opp_defense_stage = opp_team.stage[PkmStat.DEFENSE]\n",
    "\n",
    "    # Iterate over all my Pokémon and their moves to find the most damaging move\n",
    "    best_dmg_list = []\n",
    "    best_move_list = []\n",
    "\n",
    "    for i, pkm in enumerate(my_pkms):\n",
    "        # Initialize variables for the best move and its damage\n",
    "        best_damage = -np.inf\n",
    "        best_move_id = -1\n",
    "\n",
    "        if i == 0:\n",
    "            my_attack_stage = my_team.stage[PkmStat.ATTACK]\n",
    "        else:\n",
    "            my_attack_stage = 0\n",
    "\n",
    "        for j, move in enumerate(pkm.moves):\n",
    "            \n",
    "            damage = estimate_damage(move.type, pkm.type, move.power, opp_active_type, my_attack_stage,\n",
    "                                        opp_defense_stage, weather)\n",
    "            \n",
    "            # Check if the current move has higher damage than the previous best move\n",
    "            if damage > best_damage:\n",
    "                best_move_id = j + i * 4 # think for 2024 j is 0 to 3 for each\n",
    "                best_damage = damage\n",
    "\n",
    "        # get best move and dmg for each pokemon\n",
    "        best_dmg_list.append(best_damage)\n",
    "        best_move_list.append(best_move_id)\n",
    "\n",
    "    active_pkm_best_move_id = best_move_list[0]\n",
    "\n",
    "    if active_pkm_best_move_id < 0 or active_pkm_best_move_id > 3:\n",
    "        print(f\"Error: best move id { active_pkm_best_move_id } not in expected range\")\n",
    "        active_pkm_best_move_id = 0\n",
    "\n",
    "    return active_pkm_best_move_id, best_dmg_list\n",
    "\n",
    "\n",
    "def estimate_damage(move_type: PkmType, pkm_type: PkmType, move_power: float, opp_pkm_type: PkmType,\n",
    "                    attack_stage: int, defense_stage: int, weather: WeatherCondition) -> float:\n",
    "        '''\n",
    "        Not from original code. from updated repo\n",
    "        '''\n",
    "        stab = 1.5 if move_type == pkm_type else 1.\n",
    "        if (move_type == PkmType.WATER and weather == WeatherCondition.RAIN) or (\n",
    "                move_type == PkmType.FIRE and weather == WeatherCondition.SUNNY):\n",
    "            weather = 1.5\n",
    "        elif (move_type == PkmType.WATER and weather == WeatherCondition.SUNNY) or (\n",
    "                move_type == PkmType.FIRE and weather == WeatherCondition.RAIN):\n",
    "            weather = .5\n",
    "        else:\n",
    "            weather = 1.\n",
    "        stage_level = attack_stage - defense_stage\n",
    "        stage = (stage_level + 2.) / 2 if stage_level >= 0. else 2. / (np.abs(stage_level) + 2.)\n",
    "        damage = TYPE_CHART_MULTIPLIER[move_type][opp_pkm_type] * stab * weather * stage * move_power\n",
    "\n",
    "        #print(damage, move_type, pkm_type, move_power, opp_pkm_type, attack_stage, defense_stage, weather)\n",
    "        return damage\n",
    "\n",
    "\n",
    "def save_object_as_pkl(object_to_save, save_tag):\n",
    "    '''\n",
    "    Save object a pickle file\n",
    "    '''\n",
    "    with open(f'{save_tag}.pickle', 'wb') as handle:\n",
    "        pickle.dump(object_to_save, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# make a dict that has keys for 0 to 100 and values for the action dict\n",
    "def make_lookup_dict():\n",
    "    lookup_dict = {}\n",
    "    for i in range(100):\n",
    "        if i <= 40:\n",
    "            lookup_value = i // 5\n",
    "        else:\n",
    "            lookup_value = 4 + i // 10\n",
    "        lookup_dict[i] = lookup_value\n",
    "    return lookup_dict\n",
    "\n",
    "# lookup_dict = make_lookup_dict()\n",
    "# pprint.pprint(lookup_dict)\n",
    "\n",
    "def get_win_loss_reward(terminated, winner, player_index):\n",
    "    '''\n",
    "    Does a reward for winning or losing\n",
    "    winner is -1 unless a winner has been picked\n",
    "    '''\n",
    "    reward = 0.\n",
    "    if terminated:\n",
    "\n",
    "        if winner == 0 or winner == 1:\n",
    "            if winner == player_index:\n",
    "                reward = 1.\n",
    "            else:\n",
    "                reward = -1.\n",
    "        #print(f\"reward {reward} | terminated {terminated} | winner {self.env.winner} | player_index {player_index}|\")\n",
    "    return reward\n",
    "\n",
    "def get_running_mean(old_mean, old_count, new_value):\n",
    "    '''\n",
    "    '''\n",
    "    new_mean = (old_mean * old_count + new_value) / (old_count + 1)\n",
    "    \n",
    "    return new_mean\n",
    "\n",
    "\n",
    "def add_results_to_action_dict(action_dict, state_key, agent_first_move, win_int):\n",
    "    '''\n",
    "    '''\n",
    "    count_key = \"count\"\n",
    "    sum_wins_key = \"sum_wins\"\n",
    "\n",
    "    if state_key in action_dict:\n",
    "        if agent_first_move in action_dict[state_key]:\n",
    "            action_dict[state_key][agent_first_move][sum_wins_key] += win_int\n",
    "            action_dict[state_key][agent_first_move][count_key] += 1\n",
    "        else:\n",
    "            action_dict[state_key][agent_first_move] = {}\n",
    "            action_dict[state_key][agent_first_move][sum_wins_key] = win_int\n",
    "            action_dict[state_key][agent_first_move][count_key] = 1\n",
    "    else:\n",
    "        action_dict[state_key] = {}\n",
    "        action_dict[state_key][agent_first_move] = {}\n",
    "        action_dict[state_key][agent_first_move][sum_wins_key] = win_int\n",
    "        action_dict[state_key][agent_first_move][count_key] = 1\n",
    "\n",
    "def add_action_to_pkm_env_action_dict(env_action, my_dict, team_key):\n",
    "    if env_action in my_dict[team_key]:\n",
    "        my_dict[team_key][env_action] += 1\n",
    "    else:\n",
    "        my_dict[team_key][env_action] = 1\n",
    "\n",
    "    return my_dict\n",
    "\n",
    "\n",
    "\n",
    "# def add_results_to_action_dict(action_dict, state_key, agent_first_move, agent_reward):\n",
    "#     '''\n",
    "#     '''\n",
    "#     if state_key in action_dict:\n",
    "#         if agent_first_move in action_dict[state_key]:\n",
    "#             action_dict[state_key][agent_first_move][\"avg_reward\"] = get_running_mean(action_dict[state_key][agent_first_move][\"avg_reward\"],\n",
    "#                                                                                   action_dict[state_key][agent_first_move][\"count\"], agent_reward)\n",
    "#             action_dict[state_key][agent_first_move][\"count\"] += 1\n",
    "#         else:\n",
    "#             action_dict[state_key][agent_first_move] = {}\n",
    "#             action_dict[state_key][agent_first_move][\"avg_reward\"] = agent_reward\n",
    "#             action_dict[state_key][agent_first_move][\"count\"] = 1\n",
    "\n",
    "# a = (1, 2, 3)\n",
    "# type(a)\n",
    "# # combine two tuples\n",
    "# b = a + (4, 5, 6)\n",
    "# b\n",
    "# # append the value 7 to the tuple\n",
    "# b = b + (7,)\n",
    "# b\n",
    "\n",
    "\n",
    "def get_hp_array(game_state_agent, game_state_opp):\n",
    "    '''\n",
    "    '''\n",
    "    agent_pkm_hp_list = [game_state_agent.teams[0].active.hp]\n",
    "\n",
    "    for pkm in game_state_agent.teams[0].party:\n",
    "        agent_pkm_hp_list.append(pkm.hp)\n",
    "\n",
    "    opp_active_pkm_hp = game_state_opp.teams[0].active.hp\n",
    "\n",
    "    hp_array = np.array(agent_pkm_hp_list + [opp_active_pkm_hp])\n",
    "\n",
    "    return hp_array\n",
    "\n",
    "def get_hp_list(game_state_agent, game_state_opp):\n",
    "    '''\n",
    "    '''\n",
    "    agent_pkm_hp_list = [game_state_agent.teams[0].active.hp]\n",
    "\n",
    "    for pkm in game_state_agent.teams[0].party:\n",
    "        agent_pkm_hp_list.append(pkm.hp)\n",
    "\n",
    "    opp_active_pkm_hp = game_state_opp.teams[0].active.hp\n",
    "\n",
    "    hp_list = agent_pkm_hp_list + [opp_active_pkm_hp]\n",
    "\n",
    "    return hp_list\n",
    "\n",
    "def turn_game_state_into_dict_key(game_state_agent, game_state_opp,lookup_dict,\n",
    "    dmg_array,                      \n",
    "    pkm_hp_max = 480., dmg_scale_value = 600.):\n",
    "    '''\n",
    "    tuple is (\n",
    "        # HP\n",
    "        agent_active_pkm_hp, agent_party+_pkm_hp, opp_active_pkm_hp,\n",
    "        # DMG to opp\n",
    "        agent_active_pkm_dmg, agent_party_pkm_dmg,\n",
    "        # dmg from opp\n",
    "        # do this later\n",
    "        )\n",
    "    \n",
    "    If everything is on the scale of 0 to 100 picturing\n",
    "    8 buckets from 0 to 40 with increments of 5\n",
    "    6 buckets from 40 to 100 with increments of 10\n",
    "\n",
    "    preload a dict with the look up, then scal everything here\n",
    "\n",
    "    scaling dmg more than max hp so if move can do over 480 dmg has some sort of knowledge ofit\n",
    "    '''\n",
    "    # get arrays to make tuples out of for dict key\n",
    "    hp_array = get_hp_array(game_state_agent, game_state_opp)\n",
    "\n",
    "    hp_tuple = scale_hp_and_get_dict_value(hp_array, pkm_hp_max, lookup_dict)\n",
    "    dmg_tuple = scale_hp_and_get_dict_value(dmg_array, dmg_scale_value, lookup_dict)\n",
    "\n",
    "    dict_key = hp_tuple + dmg_tuple\n",
    "\n",
    "    return dict_key\n",
    "\n",
    "\n",
    "def scale_hp_and_get_dict_value(hp_array, max_hp, lookup_dict):\n",
    "    '''\n",
    "    '''\n",
    "\n",
    "    # scale by max hp then multiply by 100 to get into 0 to 99 range\n",
    "    hp_array = (hp_array / max_hp) * 100\n",
    "    # round, convert to int then clip to 0 to 99\n",
    "    hp_array = hp_array.round(0).astype(int).clip(0, 99)\n",
    "\n",
    "    \n",
    "\n",
    "    # for hp in hp_array:\n",
    "    #     hp_values_from_dict_tuple = hp_values_from_dict_tuple + (lookup_dict[hp],)\n",
    "\n",
    "    hp_values_from_dict_tuple = tuple(lookup_dict[hp] for hp in hp_array)\n",
    "\n",
    "    return hp_values_from_dict_tuple\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lookup_dict = make_lookup_dict()\n",
    "\n",
    "# a = turn_game_state_into_dict_key(game_state[0], game_state[1], lookup_dict, dmg_array)\n",
    "\n",
    "# print(a)\n",
    "\n",
    "# a = (1, 2, 3)\n",
    "# type(a)\n",
    "# # combine two tuples\n",
    "# b = a + (4, 5, 6)\n",
    "# b\n",
    "# print(b)\n",
    "# print(type(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# team_generator = RandomTeamGenerator(2)\n",
    "\n",
    "# agent_team = team_generator.get_team().get_battle_team([0, 1, ])\n",
    "# opp_team = team_generator.get_team().get_battle_team([0, 1, ])\n",
    "\n",
    "# # set new environment with teams\n",
    "# env = PkmBattleEnv((agent_team, opp_team),\n",
    "#                 encode=(False, False)) \n",
    "\n",
    "# game_state, info = env.reset()\n",
    "\n",
    "# # for pkm in game_state[0].teams[1].party:\n",
    "# #     print(pkm.hp, pkm.fainted())\n",
    "# #     # if pkm.hp > 0.0 or not pkm.fainted():\n",
    "# #     #     is_more_than_opp_pkm_alive = True\n",
    "# #     #     break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### train eval loop function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_statistical_action(action_dict, state_key):\n",
    "    '''\n",
    "    (8, 8, 6, 5, 4) {'attack': {'sum_wins': 89, 'count': 194}, 'swap': {'sum_wins': 52, 'count': 167}}\n",
    "    '''\n",
    "    best_action = 0\n",
    "    attack_key = 'attack'\n",
    "    swap_key = 'swap'\n",
    "    win_key = 'sum_wins'\n",
    "    count_key = 'count'\n",
    "\n",
    "    STOPPED HERE\n",
    "    # check if state_key in action_dict\n",
    "    # get the count and the wins\n",
    "    # plut them into the chi squared test\n",
    "\n",
    "    # if state_key in action_dict:\n",
    "    #     best_action = max(action_dict[state_key], key=action_dict[state_key].get)\n",
    "    # else:\n",
    "    #     best_action = 0\n",
    "\n",
    "    return best_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_train_eval_loop(num_battles, is_eval, run_tag, is_save=True, action_dict_to_copy=None):\n",
    "    '''\n",
    "    STOPPED HERE NEED TO WORK IN THE EVAL CODE\n",
    "    then review logic then test\n",
    "    '''\n",
    "    if is_eval and action_dict_to_copy is not None:\n",
    "        action_lookup_dict = copy.deepcopy(action_dict_to_copy)\n",
    "\n",
    "    winner_dict = {\n",
    "        0:0,\n",
    "        1:0,\n",
    "        -1:0\n",
    "    }\n",
    "\n",
    "    pkm_env_action_dict = {\n",
    "        0:{},\n",
    "        1:{},\n",
    "    }\n",
    "\n",
    "    action_state_results_dict = {}\n",
    "\n",
    "    max_episode_steps = 250\n",
    "    agent_index = 0\n",
    "\n",
    "    lookup_dict = make_lookup_dict()\n",
    "    team_generator = RandomTeamGenerator(2)\n",
    "\n",
    "    time_int = int(time.time())\n",
    "    save_tag =  f\"_{run_tag}_{time_int}\"\n",
    "    start_time = time.time()\n",
    "\n",
    "\n",
    "    for battle_idx in range(num_battles):\n",
    "        \n",
    "        agent_team = team_generator.get_team().get_battle_team([0, 1, ])\n",
    "        opp_team = team_generator.get_team().get_battle_team([0, 1, ])\n",
    "\n",
    "        # set new environment with teams\n",
    "        env = PkmBattleEnv((agent_team, opp_team), encode=(False, False)) \n",
    "\n",
    "        game_state, info = env.reset()\n",
    "\n",
    "        is_first_move = True\n",
    "        agent_first_move = None\n",
    "        state_key = None\n",
    "\n",
    "        for episode_step in range(max_episode_steps):\n",
    "            if is_first_move:\n",
    "                if np.random.rand() < 0.5:\n",
    "                    agent_pre_env_action = 0\n",
    "                    agent_first_move = 'attack'\n",
    "                else:\n",
    "                    agent_pre_env_action = 1\n",
    "                    agent_first_move = 'swap'\n",
    "                is_first_move = False\n",
    "            else:\n",
    "                agent_pre_env_action = 0\n",
    "\n",
    "            agent_env_action, agent_team_best_damage_list = turn_agent_action_into_env_action(agent_pre_env_action, game_state[0])\n",
    "            opp_action, opp_best_damage_list = get_best_active_damage_action(game_state[1])\n",
    "\n",
    "            if agent_pre_env_action == 1 and agent_env_action != 4:\n",
    "                print(\"Error agent action is 1 but env action is not 4 \")\n",
    "            elif agent_pre_env_action == 0:\n",
    "                if (agent_env_action < 0 or agent_env_action > 3):\n",
    "                    print(\"Error agent action is 0 but env action is not 0 to 3 \")\n",
    "                elif len(agent_team_best_damage_list) == 0:\n",
    "                    print(\"Error agent action is 0 but best damage list is empty\")\n",
    "                elif agent_team_best_damage_list[0] < 0:\n",
    "                    print(\"Error agent action is 0 but best damage is negative\")\n",
    "\n",
    "            if opp_action < 0 or opp_action > 3:\n",
    "                print(\"Error opp action is not 0 to 3\")\n",
    "            elif len(opp_best_damage_list) == 0:\n",
    "                print(\"Error opp best damage list is empty\")\n",
    "            elif opp_best_damage_list[0] < 0:\n",
    "                print(\"Error opp best damage is negative\")\n",
    "            \n",
    "            # get the state key\n",
    "            # only do this on the initial set up of the env\n",
    "            if state_key is None:\n",
    "                # for now just doing part dmg to opp\n",
    "                #dmg_array = np.array(agent_best_damage_list + [opp_best_damage,])\n",
    "                dmg_array = np.array(agent_team_best_damage_list)\n",
    "                state_key = turn_game_state_into_dict_key(game_state[0], game_state[1], lookup_dict, dmg_array)\n",
    "                if len(state_key) != 5:\n",
    "                    print(\"Error state key is not 5 long\")\n",
    "\n",
    "                if is_eval:\n",
    "                    # see if action look up dict says to do a different action\n",
    "                    if state_key in action_lookup_dict:\n",
    "                        # do logic for get if action is better than swap\n",
    "                        STOPPED HERE\n",
    "                        agent_pre_env_action = ...\n",
    "                        agent_env_action = turn_agent_action_into_env_action(agent_pre_env_action, game_state[0])\n",
    "\n",
    "                    pkm_env_action_dict = add_action_to_pkm_env_action_dict(agent_env_action, pkm_env_action_dict, 0)\n",
    "                    pkm_env_action_dict = add_action_to_pkm_env_action_dict(opp_action, pkm_env_action_dict, 1)\n",
    "\n",
    "            # enter action and step the env\n",
    "            action_list = [agent_env_action, opp_action]\n",
    "            game_state, _not_used_reward, terminated, truncated, info = env.step(action_list)  # for inference, we don't need reward\n",
    "\n",
    "            if episode_step == max_episode_steps - 1:\n",
    "                print('Warning: max steps reached')\n",
    "                terminated = True\n",
    "\n",
    "            if terminated:\n",
    "                winner = env.winner\n",
    "                if winner == agent_index:\n",
    "                    win_int = 1\n",
    "                else:\n",
    "                    win_int = 0\n",
    "\n",
    "                add_results_to_action_dict(action_state_results_dict, state_key, agent_first_move, win_int)\n",
    "\n",
    "                if winner in winner_dict:\n",
    "                    winner_dict[winner] += 1\n",
    "                break\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Time to run {(end_time - start_time) / 60:.3f} minutes\")\n",
    "    print(f\"Time to run {(end_time - start_time) / num_battles:.3f} seconds per battle\")\n",
    "    print(f\"Time to run {((end_time - start_time) / num_battles / 60 / 60) * 1000000:.3f} hours per million battles\")\n",
    "\n",
    "    print(winner_dict)\n",
    "\n",
    "    if is_save:\n",
    "        save_object_as_pkl(action_state_results_dict , f'action_dict_{save_tag}')\n",
    "        save_object_as_pkl(action_state_results_dict , f'action_dict_{winner_dict}')\n",
    "\n",
    "    return winner_dict, action_state_results_dict, pkm_env_action_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_wd, test_ad, test_pead = build_train_eval_loop(10, is_eval=False, run_tag=\"test\", is_save=False )\n",
    "print(test_wd)\n",
    "print(len(test_ad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Dict Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_battles = 1000000\n",
    "\n",
    "winner_dict = {\n",
    "    0:0,\n",
    "    1:0,\n",
    "    -1:0\n",
    "}\n",
    "\n",
    "pkm_env_action_dict = {\n",
    "    0:{},\n",
    "    1:{},\n",
    "}\n",
    "\n",
    "action_state_results_dict = {}\n",
    "\n",
    "max_episode_steps = 250\n",
    "agent_index = 0\n",
    "\n",
    "lookup_dict = make_lookup_dict()\n",
    "team_generator = RandomTeamGenerator(2)\n",
    "\n",
    "time_int = int(time.time())\n",
    "save_tag =  f\"_smoke_test_{time_int}\"\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "for battle_idx in range(num_battles):\n",
    "    \n",
    "    agent_team = team_generator.get_team().get_battle_team([0, 1, ])\n",
    "    opp_team = team_generator.get_team().get_battle_team([0, 1, ])\n",
    "\n",
    "    # set new environment with teams\n",
    "    env = PkmBattleEnv((agent_team, opp_team),\n",
    "                   encode=(False, False)) \n",
    "\n",
    "    game_state, info = env.reset()\n",
    "\n",
    "    is_first_move = True\n",
    "    agent_first_move = None\n",
    "    state_key = None\n",
    "\n",
    "    for episode_step in range(max_episode_steps):\n",
    "        if is_first_move:\n",
    "            if np.random.rand() < 0.5:\n",
    "                agent_pre_env_action = 0\n",
    "                agent_first_move = 'attack'\n",
    "            else:\n",
    "                agent_pre_env_action = 1\n",
    "                agent_first_move = 'swap'\n",
    "            is_first_move = False\n",
    "        else:\n",
    "            agent_pre_env_action = 0\n",
    "\n",
    "        agent_env_action, agent_team_best_damage_list = turn_agent_action_into_env_action(agent_pre_env_action, game_state[0])\n",
    "        opp_action, opp_best_damage_list = get_best_active_damage_action(game_state[1])\n",
    "\n",
    "        if agent_pre_env_action == 1 and agent_env_action != 4:\n",
    "            print(\"Error agent action is 1 but env action is not 4 \")\n",
    "        elif agent_pre_env_action == 0:\n",
    "            if (agent_env_action < 0 or agent_env_action > 3):\n",
    "                print(\"Error agent action is 0 but env action is not 0 to 3 \")\n",
    "            elif len(agent_team_best_damage_list) == 0:\n",
    "                print(\"Error agent action is 0 but best damage list is empty\")\n",
    "            elif agent_team_best_damage_list[0] < 0:\n",
    "                print(\"Error agent action is 0 but best damage is negative\")\n",
    "\n",
    "        if opp_action < 0 or opp_action > 3:\n",
    "            print(\"Error opp action is not 0 to 3\")\n",
    "        elif len(opp_best_damage_list) == 0:\n",
    "            print(\"Error opp best damage list is empty\")\n",
    "        elif opp_best_damage_list[0] < 0:\n",
    "            print(\"Error opp best damage is negative\")\n",
    "        \n",
    "        # get the state key\n",
    "        # only do this on the initial set up of the env\n",
    "        if state_key is None:\n",
    "            # for now just doing part dmg to opp\n",
    "            #dmg_array = np.array(agent_best_damage_list + [opp_best_damage,])\n",
    "            dmg_array = np.array(agent_team_best_damage_list)\n",
    "            state_key = turn_game_state_into_dict_key(game_state[0], game_state[1], lookup_dict, dmg_array)\n",
    "            if len(state_key) != 5:\n",
    "                print(\"Error state key is not 5 long\")\n",
    "\n",
    "        # enter action and step the env\n",
    "        action_list = [agent_env_action, opp_action]\n",
    "        game_state, _not_used_reward, terminated, truncated, info = env.step(action_list)  # for inference, we don't need reward\n",
    "\n",
    "        if episode_step == max_episode_steps - 1:\n",
    "            print('Warning: max steps reached')\n",
    "            terminated = True\n",
    "\n",
    "        if terminated:\n",
    "            winner = env.winner\n",
    "            if winner == agent_index:\n",
    "                win_int = 1\n",
    "            else:\n",
    "                win_int = 0\n",
    "\n",
    "            add_results_to_action_dict(action_state_results_dict, state_key, agent_first_move, win_int)\n",
    "            break\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Time to run {(end_time - start_time) / 60:.3f} minutes\")\n",
    "print(f\"Time to run {(end_time - start_time) / num_battles:.3f} seconds per battle\")\n",
    "print(f\"Time to run {((end_time - start_time) / num_battles / 60 / 60) * 1000000:.3f} hours per million battles\")\n",
    "\n",
    "print(winner_dict)\n",
    "# print(action_dict)\n",
    "\n",
    "\n",
    "save_object_as_pkl(action_state_results_dict , 'action_dict_smoke_test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(action_state_results_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### checking action dict results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k, v in action_state_results_dict.items():\n",
    "#     print(k, v)\n",
    "#     break\n",
    "\n",
    "# tuple is (\n",
    "#     # HP\n",
    "#     agent_active_pkm_hp, agent_party+_pkm_hp, opp_active_pkm_hp,\n",
    "#     # DMG to opp\n",
    "#     agent_active_pkm_dmg, agent_party_pkm_dmg,\n",
    "#     # dmg from opp\n",
    "#     # do this later\n",
    "# )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(count_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "as_copy = copy.deepcopy(action_state_results_dict)\n",
    "\n",
    "count_list = []\n",
    "\n",
    "for k, v in as_copy.items():\n",
    "    attack_count = v.get('attack', {}).get('count', 0)\n",
    "    swap_count = v.get('swap', {}).get('count', 0)\n",
    "    attack_wins = v.get('attack', {}).get('sum_wins', 0)\n",
    "    swap_wins = v.get('swap', {}).get('sum_wins', 0)\n",
    "\n",
    "    total_count = attack_count + swap_count\n",
    "    count_list.append(total_count)\n",
    "\n",
    "    if attack_count > 0:\n",
    "        attack_win_percent = attack_wins / attack_count\n",
    "    else:\n",
    "        attack_win_percent = None\n",
    "\n",
    "    if swap_count > 0:\n",
    "        swap_win_percent = swap_wins / swap_count\n",
    "    else:\n",
    "        swap_win_percent = None\n",
    "\n",
    "    if attack_win_percent is not None and swap_win_percent is not None and total_count > 100:\n",
    "        if swap_win_percent - attack_win_percent > 0.05:\n",
    "            print(k, np.round(attack_win_percent,3), np.round(swap_win_percent,3), attack_count, swap_count)\n",
    "\n",
    "    \n",
    "print(f\"count statistics {np.mean(count_list):.3f} {np.std(count_list):.3f} {np.min(count_list)} {np.max(count_list)} {np.median(count_list)}\")\n",
    "\n",
    "# find number of counts >= x\n",
    "count_array = np.array(count_list)\n",
    "for x in [50, 75, 100, 150, 200]:\n",
    "    print(x, count_array[count_array >= x].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# action_state_results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eval Agents Loop\n",
    "* based on two agents and results, see how statistically signficant the difference is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_battles = 10\n",
    "\n",
    "winner_dict = {\n",
    "    0:0,\n",
    "    1:0,\n",
    "    -1:0\n",
    "}\n",
    "\n",
    "pkm_env_action_dict = {\n",
    "    0:{},\n",
    "    1:{},\n",
    "}\n",
    "\n",
    "action_lookup_dict = copy.deepcopy(action_state_results_dict)\n",
    "\n",
    "max_episode_steps = 250\n",
    "agent_index = 0\n",
    "\n",
    "lookup_dict = make_lookup_dict()\n",
    "team_generator = RandomTeamGenerator(2)\n",
    "\n",
    "time_int = int(time.time())\n",
    "save_tag =  f\"_smoke_test_winner_dict_{time_int}\"\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "for battle_idx in range(num_battles):\n",
    "    \n",
    "    agent_team = team_generator.get_team().get_battle_team([0, 1, ])\n",
    "    opp_team = team_generator.get_team().get_battle_team([0, 1, ])\n",
    "\n",
    "    # set new environment with teams\n",
    "    env = PkmBattleEnv((agent_team, opp_team),\n",
    "                   encode=(False, False)) \n",
    " \n",
    "    game_state, info = env.reset()\n",
    "\n",
    "    # is_first_move = True\n",
    "    # agent_first_move = None\n",
    "    state_key = None\n",
    "\n",
    "    for episode_step in range(max_episode_steps):\n",
    "\n",
    "        agent_pre_env_action = 0\n",
    "        agent_env_action, agent_team_best_damage_list = turn_agent_action_into_env_action(agent_pre_env_action, game_state[0])\n",
    "        opp_action, opp_best_damage_list = get_best_active_damage_action(game_state[1])\n",
    "\n",
    "        if opp_action < 0 or opp_action > 3:\n",
    "            print(\"Error opp action is not 0 to 3\")\n",
    "        elif len(opp_best_damage_list) == 0:\n",
    "            print(\"Error opp best damage list is empty\")\n",
    "        elif opp_best_damage_list[0] < 0:\n",
    "            print(\"Error opp best damage is negative\")\n",
    "            \n",
    "        if state_key is None:\n",
    "            # for now just doing part dmg to opp\n",
    "            #dmg_array = np.array(agent_best_damage_list + [opp_best_damage,])\n",
    "            dmg_array = np.array(agent_team_best_damage_list)\n",
    "            state_key = turn_game_state_into_dict_key(game_state[0], game_state[1], lookup_dict, dmg_array)\n",
    "\n",
    "            # for now only override the initial action, could change this to possibly swap later as well\n",
    "            if state_key in action_lookup_dict:\n",
    "                agent_env_action = max(action_lookup_dict[state_key], key=action_lookup_dict[state_key].get)\n",
    "\n",
    "\n",
    "        if agent_pre_env_action == 1 and agent_env_action != 4:\n",
    "            print(\"Error agent action is 1 but env action is not 4 \")\n",
    "        elif agent_pre_env_action == 0:\n",
    "            if (agent_env_action < 0 or agent_env_action > 3):\n",
    "                print(\"Error agent action is 0 but env action is not 0 to 3 \")\n",
    "            elif len(agent_team_best_damage_list) == 0:\n",
    "                print(\"Error agent action is 0 but best damage list is empty\")\n",
    "            elif agent_team_best_damage_list[0] < 0:\n",
    "                print(\"Error agent action is 0 but best damage is negative\")\n",
    "\n",
    "        \n",
    "   \n",
    "        # enter action and step the env\n",
    "        action_list = [agent_env_action, opp_action]\n",
    "\n",
    "        pkm_env_action_dict = add_action_to_pkm_env_action_dict(agent_env_action, pkm_env_action_dict, 0)\n",
    "        pkm_env_action_dict = add_action_to_pkm_env_action_dict(opp_action, pkm_env_action_dict, 1)\n",
    "\n",
    "        #print(action_list)\n",
    "        game_state, _not_used_reward, terminated, truncated, info = env.step(action_list)  # for inference, we don't need reward\n",
    "\n",
    "        if episode_step == max_episode_steps - 1:\n",
    "            print('Warning: max steps reached')\n",
    "            terminated = True\n",
    "\n",
    "        if terminated:\n",
    "            winner = env.winner\n",
    "            if winner == agent_index:\n",
    "                win_int = 1\n",
    "            else:\n",
    "                win_int = 0\n",
    "\n",
    "            if winner in winner_dict:\n",
    "                winner_dict[winner] += 1\n",
    "\n",
    "            break\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Time to run {(end_time - start_time) / 60:.3f} minutes\")\n",
    "print(f\"Time to run {(end_time - start_time) / num_battles:.3f} seconds per battle\")\n",
    "print(f\"Time to run {((end_time - start_time) / num_battles / 60 / 60) * 1000000:.3f} hours per million battles\")\n",
    "\n",
    "print(winner_dict)\n",
    "print(pkm_env_action_dict)\n",
    "\n",
    "save_object_as_pkl(winner_dict, 'eval_winner_dict_smoke_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing 3v3 stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "(1, -1, 1, -1, 1, -1, 1, 1, 1, -1, -1, -1, 0, 0, 0, 0, -1) {'swap_1': {(1, -1, 1, -1, 1, -1, 1, 1, 1, -1, -1, -1, 0, 0, 0, 0, -1): 1, 'count': 0, 'sum_wins': 0}}\n",
      "{(1, -1, 1, -1, 1, -1, 1, 1, 1, -1, -1, -1, 0, 0, 0, 0, -1): {'swap_1': {'count': 0,\n",
      "                                                                         'sum_wins': 0,\n",
      "                                                                         (1, -1, 1, -1, 1, -1, 1, 1, 1, -1, -1, -1, 0, 0, 0, 0, -1): 1}},\n",
      " (1, 0, 2, 0, 1, 0, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 0): {'attack': {'count': 1,\n",
      "                                                                  'sum_wins': 1}},\n",
      " (1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0): {'attack': {'count': 0,\n",
      "                                                                  'sum_wins': 0,\n",
      "                                                                  (1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0): 1}},\n",
      " (1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 2, 2, 0, 0, 1, 0, 0): {'attack': {'count': 0,\n",
      "                                                                  'sum_wins': 0,\n",
      "                                                                  (1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 2, 2, 0, 0, 1, 0, 0): 1}},\n",
      " (1, 1, 1, 1, 1, 1, 3, 2, 2, 2, 2, 1, 1, 0, 0, 0, 0): {'swap_0': {'count': 0,\n",
      "                                                                  'sum_wins': 0,\n",
      "                                                                  (1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 2, 2, 0, 0, 1, 0, 0): 1}},\n",
      " (1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 2, 0, 1, 0, 0, 0): {'attack': {'count': 1,\n",
      "                                                                  'sum_wins': 1}},\n",
      " (1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0): {'swap_0': {'count': 0,\n",
      "                                                                  'sum_wins': 0,\n",
      "                                                                  (1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0): 1}},\n",
      " (1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 0, 0, 0, 1): {'swap_0': {'count': 0,\n",
      "                                                                  'sum_wins': 0,\n",
      "                                                                  (1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 0, 0, 0, 1): 1}},\n",
      " (1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 3, 1, 0, 0, 0, 0, 0): {'swap_0': {'count': 0,\n",
      "                                                                  'sum_wins': 0,\n",
      "                                                                  (1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 3, 1, 0, 0, 0, 0, 0): 1}},\n",
      " (1, 1, 2, 2, 1, 2, 1, 2, 1, 1, 2, 1, 0, 2, 0, 0, 0): {'swap_1': {'count': 0,\n",
      "                                                                  'sum_wins': 0,\n",
      "                                                                  (2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0): 1}},\n",
      " (1, 2, 1, 2, 1, 1, -1, -1, -1, -1, -1, -1, 1, 0, 0, 0, 0): {'swap_0': {'count': 0,\n",
      "                                                                        'sum_wins': 0,\n",
      "                                                                        (1, 2, 1, 2, 1, 1, -1, -1, -1, -1, -1, -1, 1, 0, 0, 0, 0): 1}},\n",
      " (1, 2, 2, 3, 2, 2, 1, 2, 2, 2, 1, 2, 0, 0, 0, 0, 2): {'attack': {'count': 0,\n",
      "                                                                  'sum_wins': 0,\n",
      "                                                                  (1, 2, 2, 3, 2, 2, 1, 2, 2, 2, 1, 2, 0, 0, 0, 0, 2): 1}},\n",
      " (1, 4, 1, 5, 1, 3, 2, 1, 1, 3, 3, 3, 0, 1, 0, 0, 2): {'swap_0': {'count': 0,\n",
      "                                                                  'sum_wins': 0,\n",
      "                                                                  (1, 4, 1, 5, 1, 3, 2, 1, 1, 3, 3, 3, 0, 1, 0, 0, 2): 1}},\n",
      " (2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0): {'attack': {'count': 0,\n",
      "                                                                  'sum_wins': 0,\n",
      "                                                                  (2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0): 1}},\n",
      " (2, 2, 2, 2, 1, 1, 1, 2, 1, 1, 2, 1, 0, 1, 1, 0, 0): {'swap_1': {'count': 0,\n",
      "                                                                  'sum_wins': 0,\n",
      "                                                                  (2, 2, 2, 2, 1, 1, 1, 2, 1, 1, 2, 1, 0, 1, 1, 0, 0): 1}},\n",
      " (3, 3, 2, 2, 2, 2, 2, 2, 2, 1, 4, 2, 0, 0, 0, 2, 2): {'swap_1': {'count': 0,\n",
      "                                                                  'sum_wins': 0,\n",
      "                                                                  (1, 2, 2, 3, 2, 2, 1, 2, 2, 2, 1, 2, 0, 0, 0, 0, 2): 1}}}\n"
     ]
    }
   ],
   "source": [
    "fp = '3v3_results\\\\3v2_2v2smtest_10_1719939243_action_state_results_dict.pickle'   \n",
    "# 2v2_2v2smtest_10_1719939082_action_state_results_dict.pickle'\n",
    "# 3v3_2v2smtest_10_1719939244_action_state_results_dict.pickle\n",
    "#3v2_2v2smtest_10_1719939243_action_state_results_dict\n",
    "\n",
    "\n",
    "with open(fp, 'rb') as handle:\n",
    "    test_dict = pickle.load(handle)\n",
    "print(len(test_dict))\n",
    "for k, v in test_dict.items():\n",
    "    print(k, v)\n",
    "    break\n",
    "pprint.pprint(test_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See if results significant\n",
    "* should probably do this with ELO?\n",
    "* these results and action files are good\n",
    "* 6/29 ish update prior to moving into expanded stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84859\n",
      "(2, 1, 3, 3, 1, 1, 1, 3) {'attack': {'sum_wins': 2, 'count': 8}, 'swap': {'sum_wins': 0, 'count': 11}}\n"
     ]
    }
   ],
   "source": [
    "fp = '2v2_state_dict_results\\\\2v2_test_0_1719717878_action_state_results_dict.pickle'\n",
    "\n",
    "with open(fp, 'rb') as handle:\n",
    "    action_dict = pickle.load(handle)\n",
    "print(len(action_dict))\n",
    "for k, v in action_dict.items():\n",
    "    print(k, v)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "def get_chi_square_test_from_action_dict(\n",
    "    action_dict,\n",
    "    state_key,\n",
    "    min_total_count=100,\n",
    "    min_swap_count=50,\n",
    "    min_attack_count=50,\n",
    "    swap_key='swap', attack_key='attack',\n",
    "    sum_wins_key='sum_wins', count_key='count',\n",
    "    is_print_statistics=False):\n",
    "\n",
    "    attack_action = 0\n",
    "    swap_party_zero_action = 1\n",
    "    swap_party_one_action = 2\n",
    "\n",
    "    is_use_p_value = False\n",
    "    is_swap_better = False\n",
    "    p_value = None\n",
    "    swap_win_rate_better_rate = 0.\n",
    "    recommended_action = attack_action\n",
    "\n",
    "    try:\n",
    "        if state_key in action_dict:\n",
    "\n",
    "            if swap_key in action_dict[state_key] and attack_key in action_dict[state_key]:\n",
    "                swap_wins = action_dict[state_key][swap_key][sum_wins_key]\n",
    "                swap_count = action_dict[state_key][swap_key][count_key]\n",
    "                attack_wins = action_dict[state_key][attack_key][sum_wins_key]\n",
    "                attack_count = action_dict[state_key][attack_key][count_key]\n",
    "\n",
    "                total_count = swap_count + attack_count\n",
    "\n",
    "                if total_count > min_total_count and swap_count > min_swap_count and attack_count > min_attack_count:\n",
    "\n",
    "                    swap_win_percent = swap_wins / swap_count\n",
    "                    attack_win_percent = attack_wins / attack_count\n",
    "                    \n",
    "                    if swap_win_percent > attack_win_percent:\n",
    "                        is_swap_better = True\n",
    "                        swap_win_rate_better_rate = swap_win_percent - attack_win_percent\n",
    "                    else:\n",
    "                        is_swap_better = False\n",
    "                        swap_win_rate_better_rate = 0.\n",
    "\n",
    "                    # chi squared table breaks down if any 0 values\n",
    "                    # really should not have less than 5\n",
    "                    if attack_wins == attack_count:\n",
    "                        recommended_action = attack_action\n",
    "                        # choose attack as attack always wins\n",
    "                        if is_print_statistics:\n",
    "                            print(\"Attack always wins\")\n",
    "                            print(f\"Swap win rate: {swap_wins / swap_count:.3f} | Count {swap_count}\")\n",
    "                            print(f\"Attack win rate: {attack_wins / attack_count:.3f} | Count {attack_count}\")\n",
    "                    elif swap_wins == swap_count:\n",
    "                        # choose swap\n",
    "                        is_use_p_value = True\n",
    "                        is_swap_better = True\n",
    "                        p_value = 0.\n",
    "                        recommended_action = swap_party_zero_action\n",
    "                        if is_print_statistics:\n",
    "                            print(\"swap always wins, choosing swap\")\n",
    "                            print(f\"Swap win rate: {swap_wins / swap_count:.3f} | Count {swap_count}\")\n",
    "                            print(f\"Attack win rate: {attack_wins / attack_count:.3f} | Count {attack_count}\")\n",
    "                    elif swap_wins == 0:\n",
    "                        recommended_action = attack_action\n",
    "                        # swap always loses\n",
    "                        if is_print_statistics:\n",
    "                            print(\"Swap always loses\")\n",
    "                            print(f\"Swap win rate: {swap_wins / swap_count:.3f} | Count {swap_count}\")\n",
    "                            print(f\"Attack win rate: {attack_wins / attack_count:.3f} | Count {attack_count}\")\n",
    "                    elif attack_wins == 0:\n",
    "                        # attack always loses and swap won at least once so choose swap\n",
    "                        is_use_p_value = True\n",
    "                        is_swap_better = True\n",
    "                        p_value = 0.\n",
    "                        recommended_action = swap_party_zero_action\n",
    "                        if is_print_statistics:\n",
    "                            print(\"Attack always loses, choosing swap \")\n",
    "                            print(f\"Swap win rate: {swap_wins / swap_count:.3f} | Count {swap_count}\")\n",
    "                            print(f\"Attack win rate: {attack_wins / attack_count:.3f} | Count {attack_count}\")\n",
    "                    else:\n",
    "                        contingency_table = [[swap_wins, swap_count - swap_wins], [attack_wins, attack_count - attack_wins]]\n",
    "                        chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "                        is_use_p_value = True\n",
    "\n",
    "                        if is_swap_better:\n",
    "                            if p_value < 0.25:\n",
    "                                recommended_action = swap_party_zero_action\n",
    "                            elif swap_win_rate_better_rate >= .1:\n",
    "                                recommended_action = swap_party_zero_action\n",
    "                            elif swap_win_rate_better_rate >= .05 and p_value < .6:\n",
    "                                recommended_action = swap_party_zero_action\n",
    "\n",
    "                        if is_print_statistics:\n",
    "                            #print(f'Swap Win : { win_loss_draw1[0] / sum(win_loss_draw1):.3f}')\n",
    "                            print(f\"Swap win rate: {swap_wins / swap_count:.3f} | Count {swap_count}\")\n",
    "                            print(f\"Attack win rate: {attack_wins / attack_count:.3f} | Count {attack_count}\")\n",
    "                            print(f'Chi-square statistic: {chi2:.3f}')\n",
    "                            print(f'P-value: {p_value:.5f}')\n",
    "\n",
    "        else:\n",
    "            is_use_p_value = False\n",
    "            is_swap_better = False\n",
    "            p_value = None\n",
    "            swap_win_rate_better_rate = 0.\n",
    "            recommended_action = attack_action\n",
    "    except Exception as e:\n",
    "        print(\"Error: in chi square test \", str(e) )\n",
    "        is_use_p_value = False\n",
    "        is_swap_better = False\n",
    "        p_value = None\n",
    "        swap_win_rate_better_rate = 0.\n",
    "        recommended_action = attack_action\n",
    "    \n",
    "    return recommended_action, swap_win_rate_better_rate, is_use_p_value, is_swap_better, p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### tune p value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- (1, 1, 1, 3, 1, 1, 3, 1) ---\n",
      "Swap win rate: 0.591 | Count 66\n",
      "Attack win rate: 0.529 | Count 68\n",
      "Chi-square statistic: 0.295\n",
      "P-value: 0.58720\n",
      "______\n",
      "--- (2, 1, 2, 3, 2, 1, 2, 1) ---\n",
      "Swap win rate: 0.321 | Count 53\n",
      "Attack win rate: 0.246 | Count 57\n",
      "Chi-square statistic: 0.440\n",
      "P-value: 0.50719\n",
      "______\n",
      "--- (1, 2, 1, 4, 1, 2, 2, 3) ---\n",
      "Swap win rate: 0.596 | Count 99\n",
      "Attack win rate: 0.543 | Count 105\n",
      "Chi-square statistic: 0.389\n",
      "P-value: 0.53266\n",
      "______\n",
      "--- (3, 1, 3, 1, 3, 1, 1, 1) ---\n",
      "Swap win rate: 0.576 | Count 59\n",
      "Attack win rate: 0.500 | Count 52\n",
      "Chi-square statistic: 0.377\n",
      "P-value: 0.53936\n",
      "______\n",
      "--- (1, 3, 1, 2, 1, 2, 3, 2) ---\n",
      "Swap win rate: 0.672 | Count 64\n",
      "Attack win rate: 0.613 | Count 75\n",
      "Chi-square statistic: 0.291\n",
      "P-value: 0.58952\n",
      "______\n",
      "84859 438\n"
     ]
    }
   ],
   "source": [
    "num_iters = -1\n",
    "num_swaps_better = 0\n",
    "# num_swaps_better_max = 5\n",
    "p_value_list = []\n",
    "min_p_value = 1.\n",
    "\n",
    "# testing function\n",
    "def is_swap_allowed_symmetric_state(current_state, num_agent_pkm, num_opp_pkm):\n",
    "    '''\n",
    "    Do not allow swaps if the result would mean the same state\n",
    "    '''\n",
    "\n",
    "    if num_agent_pkm == 2 and num_opp_pkm == 2:\n",
    "        # 8 keys\n",
    "        # agent active to opp active\n",
    "        # agent active to opp party\n",
    "        # agent party to opp active\n",
    "        # agent party to opp party\n",
    "        # opp active to agent active\n",
    "        # opp active to agent party\n",
    "        # opp party to agent active\n",
    "        # opp party to agent party\n",
    "        # if a swap occurs\n",
    "        #   index 0 becomes index 2 and index 1 becomes index 3\n",
    "        #   index 4 becomes index 5 and index 6 becomes index 7\n",
    "\n",
    "        if current_state[0] == current_state[2] and current_state[1] == current_state[3] \\\n",
    "            and current_state[4] == current_state[5] and current_state[6] == current_state[7]:\n",
    "            print(\"Testing: same state, swap not allowed\")\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "    return True\n",
    "    \n",
    "for test_key, _ in action_dict.items():\n",
    "    num_iters += 1\n",
    "    recommended_action, swap_win_rate_better_rate, is_use_p_value, is_swap_better, p_value = get_chi_square_test_from_action_dict(\n",
    "        action_dict, test_key, is_print_statistics=False)\n",
    "\n",
    "    if recommended_action == 1:\n",
    "        num_swaps_better += 1\n",
    "        if p_value > .5:\n",
    "            print(f\"--- {test_key} ---\")\n",
    "            recommended_action, swap_win_rate_better_rate, is_use_p_value, is_swap_better, p_value = get_chi_square_test_from_action_dict(\n",
    "                action_dict, test_key, is_print_statistics=True)\n",
    "            print(\"______\")\n",
    "    # if is_swap_better and p < min_p_value:\n",
    "    #     p_value_list.append(p)\n",
    "    #     num_swaps_better += 1\n",
    "\n",
    "    #     if p >= .9:\n",
    "    #         print(f\"--- {test_key} ---\")\n",
    "    #         is_use_p, is_swap_better, p = get_chi_square_test_from_action_dict(action_dict, test_key, is_print_statistics=True)\n",
    "    #         print(\"______\")\n",
    "\n",
    "print(len(action_dict), num_swaps_better)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 1, 2, 1, 2, 2, 2, 5) 1\n"
     ]
    }
   ],
   "source": [
    "print(test_key, min(test_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- (1, 1, 1, 2, -1, -1, 2, 1) ---\n",
      "Swap win rate: 0.683 | Count 142\n",
      "Attack win rate: 0.545 | Count 165\n",
      "Chi-square statistic: 5.509\n",
      "P-value: 0.01892\n",
      "______\n",
      "--- (1, 1, 1, 1, 1, 3, -1, -1) ---\n",
      "Swap win rate: 0.847 | Count 59\n",
      "Attack win rate: 0.755 | Count 151\n",
      "Chi-square statistic: 1.615\n",
      "P-value: 0.20375\n",
      "______\n",
      "--- (1, 1, 2, 2, -1, -1, 2, 1) ---\n",
      "Swap win rate: 0.667 | Count 54\n",
      "Attack win rate: 0.541 | Count 61\n",
      "Chi-square statistic: 1.398\n",
      "P-value: 0.23707\n",
      "______\n",
      "--- (2, 1, 2, 2, 1, 2, -1, -1) ---\n",
      "Swap win rate: 0.183 | Count 71\n",
      "Attack win rate: 0.092 | Count 109\n",
      "Chi-square statistic: 2.452\n",
      "P-value: 0.11737\n",
      "______\n",
      "--- (1, 1, 1, 2, 1, 2, -1, -1) ---\n",
      "Swap win rate: 0.461 | Count 219\n",
      "Attack win rate: 0.400 | Count 477\n",
      "Chi-square statistic: 2.033\n",
      "P-value: 0.15389\n",
      "______\n",
      "--- (2, 1, 2, 2, -1, -1, -1, -1) ---\n",
      "Swap win rate: 0.355 | Count 124\n",
      "Attack win rate: 0.278 | Count 176\n",
      "Chi-square statistic: 1.645\n",
      "P-value: 0.19958\n",
      "______\n",
      "--- (2, 1, 2, 2, -1, -1, 1, 1) ---\n",
      "Swap win rate: 0.265 | Count 83\n",
      "Attack win rate: 0.069 | Count 160\n",
      "Chi-square statistic: 16.312\n",
      "P-value: 0.00005\n",
      "______\n",
      "--- (2, 1, 1, 2, -1, -1, 1, 1) ---\n",
      "Swap win rate: 0.176 | Count 91\n",
      "Attack win rate: 0.070 | Count 158\n",
      "Chi-square statistic: 5.683\n",
      "P-value: 0.01713\n",
      "______\n",
      "--- (1, 1, 1, 3, -1, -1, -1, -1) ---\n",
      "Swap win rate: 0.509 | Count 53\n",
      "Attack win rate: 0.342 | Count 76\n",
      "Chi-square statistic: 2.954\n",
      "P-value: 0.08568\n",
      "______\n",
      "--- (2, 1, 1, 2, -1, -1, -1, -1) ---\n",
      "Swap win rate: 0.384 | Count 99\n",
      "Attack win rate: 0.290 | Count 124\n",
      "Chi-square statistic: 1.770\n",
      "P-value: 0.18338\n",
      "______\n",
      "--- (2, 2, 1, 2, -1, -1, 2, 1) ---\n",
      "Swap win rate: 0.224 | Count 67\n",
      "Attack win rate: 0.086 | Count 70\n",
      "Chi-square statistic: 4.027\n",
      "P-value: 0.04478\n",
      "______\n",
      "checking unknown states 44070 11\n"
     ]
    }
   ],
   "source": [
    "# testing if unkowns in the state key\n",
    "num_iters = -1\n",
    "num_swaps_better = 0\n",
    "# num_swaps_better_max = 5\n",
    "p_value_list = []\n",
    "min_p_value = 1.\n",
    "\n",
    "for test_key, _ in action_dict.items():\n",
    "    num_iters += 1\n",
    "    recommended_action, swap_win_rate_better_rate, is_use_p_value, is_swap_better, p_value = get_chi_square_test_from_action_dict(\n",
    "        action_dict, test_key, is_print_statistics=False)\n",
    "\n",
    "    if recommended_action == 1:\n",
    "        if min(test_key) == -1:\n",
    "            num_swaps_better += 1\n",
    "            print(f\"--- {test_key} ---\")\n",
    "            recommended_action, swap_win_rate_better_rate, is_use_p_value, is_swap_better, p_value = get_chi_square_test_from_action_dict(\n",
    "                action_dict, test_key, is_print_statistics=True)\n",
    "            print(\"______\")\n",
    "\n",
    "        # # any unkowns in the state\n",
    "        # num_swaps_better += 1\n",
    "        # if p_value > .5:\n",
    "        #     print(f\"--- {test_key} ---\")\n",
    "        #     recommended_action, swap_win_rate_better_rate, is_use_p_value, is_swap_better, p_value = get_chi_square_test_from_action_dict(\n",
    "        #         action_dict, test_key, is_print_statistics=True)\n",
    "        #     print(\"______\")\n",
    "    # if is_swap_better and p < min_p_value:\n",
    "    #     p_value_list.append(p)\n",
    "    #     num_swaps_better += 1\n",
    "\n",
    "    #     if p >= .9:\n",
    "    #         print(f\"--- {test_key} ---\")\n",
    "    #         is_use_p, is_swap_better, p = get_chi_square_test_from_action_dict(action_dict, test_key, is_print_statistics=True)\n",
    "    #         print(\"______\")\n",
    "\n",
    "print(\"checking unknown states\", len(action_dict), num_swaps_better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: same state, swap not allowed\n",
      "Error,\n",
      "--- (2, 2, 2, 2, 1, 1, 1, 1) ---\n",
      "Attack always loses, choosing swap \n",
      "Swap win rate: 0.002 | Count 2865\n",
      "Attack win rate: 0.000 | Count 5921\n",
      "______\n",
      "Testing: same state, swap not allowed\n",
      "Error,\n",
      "--- (3, 1, 3, 1, 1, 1, 1, 1) ---\n",
      "Attack always loses, choosing swap \n",
      "Swap win rate: 0.003 | Count 337\n",
      "Attack win rate: 0.000 | Count 445\n",
      "______\n",
      "Testing: same state, swap not allowed\n",
      "Error,\n",
      "--- (3, 1, 3, 1, -1, -1, 1, 1) ---\n",
      "Swap win rate: 0.395 | Count 86\n",
      "Attack win rate: 0.269 | Count 104\n",
      "Chi-square statistic: 2.856\n",
      "P-value: 0.09101\n",
      "______\n",
      "84859 438\n"
     ]
    }
   ],
   "source": [
    "# testing function\n",
    "def is_swap_allowed_symmetric_state(current_state, num_agent_pkm, num_opp_pkm):\n",
    "    '''\n",
    "    Do not allow swaps if the result would mean the same state\n",
    "    '''\n",
    "\n",
    "    if num_agent_pkm == 2 and num_opp_pkm == 2:\n",
    "        # 8 keys\n",
    "        # agent active to opp active\n",
    "        # agent active to opp party\n",
    "        # agent party to opp active\n",
    "        # agent party to opp party\n",
    "        # opp active to agent active\n",
    "        # opp active to agent party\n",
    "        # opp party to agent active\n",
    "        # opp party to agent party\n",
    "        # if a swap occurs\n",
    "        #   index 0 becomes index 2 and index 1 becomes index 3\n",
    "        #   index 4 becomes index 5 and index 6 becomes index 7\n",
    "\n",
    "        if current_state[0] == current_state[2] and current_state[1] == current_state[3] \\\n",
    "            and current_state[4] == current_state[5] and current_state[6] == current_state[7]:\n",
    "            print(\"Testing: same state, swap not allowed\")\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "    return True\n",
    "\n",
    "num_iters = -1\n",
    "num_swaps_better = 0\n",
    "# num_swaps_better_max = 5\n",
    "p_value_list = []\n",
    "min_p_value = 1.\n",
    "\n",
    "for test_key, _ in action_dict.items():\n",
    "    num_iters += 1\n",
    "    recommended_action, swap_win_rate_better_rate, is_use_p_value, is_swap_better, p_value = get_chi_square_test_from_action_dict(\n",
    "        action_dict, test_key, is_print_statistics=False)\n",
    "\n",
    "    if recommended_action == 1:\n",
    "        num_swaps_better += 1\n",
    "\n",
    "        if not is_swap_allowed_symmetric_state(test_key, 2, 2):\n",
    "            print(\"Error,\")\n",
    "            print(f\"--- {test_key} ---\")\n",
    "            recommended_action, swap_win_rate_better_rate, is_use_p_value, is_swap_better, p_value = get_chi_square_test_from_action_dict(\n",
    "                action_dict, test_key, is_print_statistics=True)\n",
    "            print(\"______\")\n",
    "        # if p_value > .5:\n",
    "        #     print(f\"--- {test_key} ---\")\n",
    "        #     recommended_action, swap_win_rate_better_rate, is_use_p_value, is_swap_better, p_value = get_chi_square_test_from_action_dict(\n",
    "        #         action_dict, test_key, is_print_statistics=True)\n",
    "        #     print(\"______\")\n",
    "    # if is_swap_better and p < min_p_value:\n",
    "    #     p_value_list.append(p)\n",
    "    #     num_swaps_better += 1\n",
    "\n",
    "    #     if p >= .9:\n",
    "    #         print(f\"--- {test_key} ---\")\n",
    "    #         is_use_p, is_swap_better, p = get_chi_square_test_from_action_dict(action_dict, test_key, is_print_statistics=True)\n",
    "    #         print(\"______\")\n",
    "\n",
    "print(len(action_dict), num_swaps_better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- (0, 0, 0, 0, 0, 0, 0, 0) ---\n",
      "False None\n",
      "______\n",
      "--- (1, 1, 1, 1, 1, 1, 1, 1) ---\n",
      "Swap win rate: 0.285 | Count 56373\n",
      "Attack win rate: 0.503 | Count 89648\n",
      "Chi-square statistic: 6768.218\n",
      "P-value: 0.00000\n",
      "True 0.0\n",
      "______\n",
      "--- (2, 2, 2, 2, 2, 2, 2, 2) ---\n",
      "Swap win rate: 0.175 | Count 371\n",
      "Attack win rate: 0.468 | Count 453\n",
      "Chi-square statistic: 77.044\n",
      "P-value: 0.00000\n",
      "True 1.6719395982814362e-18\n",
      "______\n",
      "--- (3, 3, 3, 3, 3, 3, 3, 3) ---\n",
      "False None\n",
      "______\n",
      "--- (4, 4, 4, 4, 4, 4, 4, 4) ---\n",
      "False None\n",
      "______\n"
     ]
    }
   ],
   "source": [
    "# test_key_list = [tuple([x]*8) for x in range(10)]\n",
    "# test_key_list\n",
    "\n",
    "test_key_list = [tuple([x]*8) for x in range(5)]\n",
    "\n",
    "for test_key in test_key_list:\n",
    "    print(f\"--- {test_key} ---\")\n",
    "    is_use_p, is_swap_better, p = get_chi_square_test_from_action_dict(action_dict, test_key, is_print_statistics=True)\n",
    "    print(is_use_p, p)\n",
    "    print(\"______\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- (1, 1, 1, 2, -1, -1, 2, 1) ---\n",
      "Swap win rate: 0.683 | Count 142\n",
      "Attack win rate: 0.545 | Count 165\n",
      "Chi-square statistic: 5.509\n",
      "P-value: 0.01892\n",
      "True 0.018922771494133066\n",
      "______\n",
      "--- (2, 2, 1, 2, 2, 2, 2, 1) ---\n",
      "Swap win rate: 0.494 | Count 156\n",
      "Attack win rate: 0.095 | Count 242\n",
      "Chi-square statistic: 77.984\n",
      "P-value: 0.00000\n",
      "True 1.038903566590097e-18\n",
      "______\n",
      "--- (1, 2, 1, 2, 1, 2, 1, 1) ---\n",
      "Swap win rate: 0.138 | Count 812\n",
      "Attack win rate: 0.130 | Count 3198\n",
      "Chi-square statistic: 0.259\n",
      "P-value: 0.61095\n",
      "True 0.6109535241152642\n",
      "______\n",
      "--- (1, 1, 1, 2, 1, 1, 1, 1) ---\n",
      "Swap win rate: 0.267 | Count 9139\n",
      "Attack win rate: 0.254 | Count 13881\n",
      "Chi-square statistic: 4.629\n",
      "P-value: 0.03144\n",
      "True 0.03144015349882742\n",
      "______\n",
      "--- (2, 2, 2, 3, 1, 2, 2, 2) ---\n",
      "Swap win rate: 0.186 | Count 59\n",
      "Attack win rate: 0.067 | Count 75\n",
      "Chi-square statistic: 3.438\n",
      "P-value: 0.06370\n",
      "True 0.0636988410853709\n",
      "______\n"
     ]
    }
   ],
   "source": [
    "num_iters = -1\n",
    "num_swaps_better = 0\n",
    "num_swaps_better_max = 5\n",
    "\n",
    "for test_key, _ in action_dict.items():\n",
    "    num_iters += 1\n",
    "    is_use_p, is_swap_better, p = get_chi_square_test_from_action_dict(action_dict, test_key, is_print_statistics=False)\n",
    "\n",
    "    if is_swap_better:\n",
    "        print(f\"--- {test_key} ---\")\n",
    "        is_use_p, is_swap_better, p = get_chi_square_test_from_action_dict(action_dict, test_key, is_print_statistics=True)\n",
    "        print(is_use_p, p)\n",
    "        print(\"______\")\n",
    "        num_swaps_better += 1\n",
    "        if num_swaps_better >= num_swaps_better_max:\n",
    "            break\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### fucking awesome. some of these make a lot of sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'swap': {'sum_wins': 57, 'count': 57},\n",
       " 'attack': {'sum_wins': 93, 'count': 93}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_dict[test_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The internally computed table of expected frequencies has a zero element at (0, 1).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test_key, _ \u001b[38;5;129;01min\u001b[39;00m action_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m      7\u001b[0m     num_iters \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m----> 8\u001b[0m     is_use_p, is_swap_better, p \u001b[38;5;241m=\u001b[39m \u001b[43mget_chi_square_test_from_action_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_print_statistics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_swap_better \u001b[38;5;129;01mand\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m.1\u001b[39m:\n\u001b[0;32m     11\u001b[0m         p_value_list\u001b[38;5;241m.\u001b[39mappend(p)\n",
      "Cell \u001b[1;32mIn[30], line 30\u001b[0m, in \u001b[0;36mget_chi_square_test_from_action_dict\u001b[1;34m(action_dict, state_key, min_total_count, min_swap_count, min_attack_count, swap_key, attack_key, sum_wins_key, count_key, is_print_statistics)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m total_count \u001b[38;5;241m>\u001b[39m min_total_count \u001b[38;5;129;01mand\u001b[39;00m swap_count \u001b[38;5;241m>\u001b[39m min_swap_count \u001b[38;5;129;01mand\u001b[39;00m attack_count \u001b[38;5;241m>\u001b[39m min_attack_count:\n\u001b[0;32m     29\u001b[0m     contingency_table \u001b[38;5;241m=\u001b[39m [[swap_wins, swap_count \u001b[38;5;241m-\u001b[39m swap_wins], [attack_wins, attack_count \u001b[38;5;241m-\u001b[39m attack_wins]]\n\u001b[1;32m---> 30\u001b[0m     chi2, p_value, dof, expected \u001b[38;5;241m=\u001b[39m \u001b[43mchi2_contingency\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontingency_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m     is_use_p_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     33\u001b[0m     swap_win_percent \u001b[38;5;241m=\u001b[39m swap_wins \u001b[38;5;241m/\u001b[39m swap_count\n",
      "File \u001b[1;32mc:\\Users\\james\\github_repos\\pokemon-vgc-engine\\vgc\\lib\\site-packages\\scipy\\stats\\contingency.py:340\u001b[0m, in \u001b[0;36mchi2_contingency\u001b[1;34m(observed, correction, lambda_)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(expected \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;66;03m# Include one of the positions where expected is zero in\u001b[39;00m\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;66;03m# the exception message.\u001b[39;00m\n\u001b[0;32m    339\u001b[0m     zeropos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mnonzero(expected \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)))[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 340\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe internally computed table of expected \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    341\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequencies has a zero element at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzeropos\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;66;03m# The degrees of freedom\u001b[39;00m\n\u001b[0;32m    344\u001b[0m dof \u001b[38;5;241m=\u001b[39m expected\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m-\u001b[39m \u001b[38;5;28msum\u001b[39m(expected\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m+\u001b[39m expected\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: The internally computed table of expected frequencies has a zero element at (0, 1)."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "def chi_square_test(win_loss_draw1, win_loss_draw2):\n",
    "    \"\"\"\n",
    "    Performs a Chi-square test on two entities with win, loss, and draw counts.\n",
    "    \n",
    "    Parameters:\n",
    "    - win_loss_draw1: A list or tuple of win, loss, and draw counts for entity 1 (e.g., [wins, losses, draws]).\n",
    "    - win_loss_draw2: A list or tuple of win, loss, and draw counts for entity 2.\n",
    "    \n",
    "    Returns:\n",
    "    - Chi-square statistic, p-value, and interpretation as a string.\n",
    "    \"\"\"\n",
    "    # Create a contingency table\n",
    "    contingency_table = [win_loss_draw1, win_loss_draw2]\n",
    "    \n",
    "    # Perform the Chi-square test\n",
    "    chi2, pval, dof, expected = chi2_contingency(contingency_table)\n",
    "    \n",
    "    # Interpret the results\n",
    "    interpretation = (\"There is a statistically significant difference in outcomes between the two entities.\"\n",
    "                      if pval < 0.05 else\n",
    "                      \"There is no statistically significant difference in outcomes between the two entities.\")\n",
    "    \n",
    "    print(f'Player 1 Win rate: { win_loss_draw1[0] / sum(win_loss_draw1):.3f}')\n",
    "\n",
    "\n",
    "    print(f'Chi-square statistic: {chi2:.3f}')\n",
    "    print(f'P-value: {pval:.5f}')\n",
    "\n",
    "    return chi2, pval, interpretation\n",
    "\n",
    "# # Example usage\n",
    "#chi2, pval, interpretation = chi_square_test([120, 80, 50], [130, 70, 60])\n",
    "\n",
    "# chi2, pval, interpretation = chi_square_test([winner_dict[0],\n",
    "#                                               winner_dict[1],\n",
    "#                                               #winner_dict[-1]\n",
    "#                                               ],\n",
    "#                                              [winner_dict[1],\n",
    "#                                               winner_dict[0],\n",
    "#                                               #winner_dict[-1]\n",
    "#                                               ],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi2, pval, interpretation = chi_square_test([winner_dict[0],\n",
    "#                                               winner_dict[1],\n",
    "#                                               #winner_dict[-1]\n",
    "#                                               ],\n",
    "#                                              [winner_dict[1],\n",
    "#                                               winner_dict[0],\n",
    "#                                               #winner_dict[-1]\n",
    "#                                               ],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test where it is significant\n",
    "\n",
    "for x in range(150, 200, 5):\n",
    "    winner_dict = {\n",
    "        0:x,\n",
    "        1:300-x,\n",
    "        -1:0\n",
    "    }\n",
    "    print(\"--- x is \", x)\n",
    "    chi2, pval, interpretation = chi_square_test([winner_dict[0],\n",
    "                                                winner_dict[1],\n",
    "                                                #winner_dict[-1]\n",
    "                                                ],\n",
    "                                                [winner_dict[1],\n",
    "                                                winner_dict[0],\n",
    "                                                #winner_dict[-1]\n",
    "                                                ],)\n",
    "    print(\"________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "\n",
    "def compare_rates(successes_group1, observations_group1, successes_group2, observations_group2):\n",
    "    \"\"\"\n",
    "    Compares two observed rates using a two-sample t-test and prints the t-statistic and p-value.\n",
    "    \n",
    "    Parameters:\n",
    "    - successes_group1: Number of successes in group 1\n",
    "    - observations_group1: Number of observations in group 1\n",
    "    - successes_group2: Number of successes in group 2\n",
    "    - observations_group2: Number of observations in group 2\n",
    "    \"\"\"\n",
    "    # Calculate rates\n",
    "    rate_group1 = successes_group1 / observations_group1\n",
    "    rate_group2 = successes_group2 / observations_group2\n",
    "\n",
    "    # Convert rates to \"success\" arrays\n",
    "    data_group1 = np.array([1] * successes_group1 + [0] * (observations_group1 - successes_group1))\n",
    "    data_group2 = np.array([1] * successes_group2 + [0] * (observations_group2 - successes_group2))\n",
    "\n",
    "    # Perform the two-sample t-test\n",
    "    stat, pval = ttest_ind(data_group1, data_group2)\n",
    "\n",
    "    # Print rounded t-statistic and p-value\n",
    "    print(\"Rates: {:.3f} vs. {:.3f}\".format(rate_group1, rate_group2))\n",
    "    print(f'T-statistic: {stat:.5f}')\n",
    "    print(f'P-value: {pval:.5f}')\n",
    "\n",
    "# Example usage\n",
    "#compare_rates(45, 100, 50, 120)\n",
    "\n",
    "compare_rates(winner_dict[0], num_battles, winner_dict[1], num_battles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_wins in [150, 160, 170, 175, 200, 225, 250, 275]:\n",
    "    print(test_wins)\n",
    "    compare_rates(test_wins, num_battles, num_battles-test_wins, num_battles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(episode_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.step(action_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".266 / 60 * 1000000 /60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing dict size with raw values\n",
    "* so with 5m iters, like 4.7m different dict values\n",
    "* so some grouping needs to be done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iters = 5000000\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "raw_stats_dict = {}\n",
    "team_generator = RandomTeamGenerator(2)\n",
    "\n",
    "for i in range(test_iters):\n",
    "    agent_team = team_generator.get_team().get_battle_team([0, 1, ])\n",
    "    opp_team = team_generator.get_team().get_battle_team([0, 1, ])\n",
    "\n",
    "    game_state, info = env.reset()\n",
    "\n",
    "    env = PkmBattleEnv((agent_team, opp_team), encode=(False, False)) \n",
    "\n",
    "    game_state, info = env.reset()\n",
    "\n",
    "    _agent_env_action, agent_team_best_damage_list = turn_agent_action_into_env_action(0, game_state[0])\n",
    "    _opp_action, opp_best_damage_list = get_best_active_damage_action(game_state[1])\n",
    "\n",
    "    hp_list = get_hp_list(game_state[0], game_state[1])\n",
    "    #print(hp_list, agent_team_best_damage_list, opp_best_damage_list)\n",
    "\n",
    "    state_tuple = tuple(hp_list + agent_team_best_damage_list + opp_best_damage_list)\n",
    "    #print(state_tuple)\n",
    "\n",
    "    if state_tuple in raw_stats_dict:\n",
    "        raw_stats_dict[state_tuple] += 1\n",
    "    else:\n",
    "        raw_stats_dict[state_tuple] = 1\n",
    "\n",
    "time_end = time.time()\n",
    "print(f\"Time to run {time_end - time_start:.3f} seconds\")\n",
    "\n",
    "print(len(raw_stats_dict))\n",
    "\n",
    "save_object_as_pkl(raw_stats_dict, 'raw_state_dict_smoke_test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10956.973 /60 /60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_hp_act_dict = copy.deepcopy(raw_stats_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the distribution of HP values and dmg values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in raw_hp_act_dict.items():\n",
    "    print(k,v)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first 3 are HP, next four are dmg\n",
    "hp_dict_count = {}\n",
    "dmg_dict_count = {}\n",
    "hp_list = []\n",
    "dmg_list = []\n",
    "\n",
    "for k, _ in raw_hp_act_dict.items():\n",
    "    hp_key = k[:3]\n",
    "    dmg_key = k[3:]\n",
    "\n",
    "    for hp_value in hp_key:\n",
    "        if hp_value in hp_dict_count:\n",
    "            hp_dict_count[hp_value] += 1\n",
    "        else:\n",
    "            hp_dict_count[hp_value] = 1\n",
    "        hp_list.append(hp_value)\n",
    "\n",
    "    for dmg_value in dmg_key:\n",
    "        if dmg_value in dmg_dict_count:\n",
    "            dmg_dict_count[dmg_value] += 1\n",
    "        else:\n",
    "            dmg_dict_count[dmg_value] = 1\n",
    "        dmg_list.append(dmg_value)\n",
    "    \n",
    "\n",
    "print(hp_dict_count)\n",
    "print(dmg_dict_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### notes\n",
    "* so very few HP values\n",
    "* also not that many low dmg values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{120.0: 3779517,\n",
      " 156.0: 3378332,\n",
      " 192.0: 2453402,\n",
      " 228.0: 1692512,\n",
      " 264.0: 1144966,\n",
      " 300.0: 758680,\n",
      " 336.0: 484424,\n",
      " 372.0: 296296,\n",
      " 408.0: 164303,\n",
      " 444.0: 75229,\n",
      " 480.0: 22651}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint({336.0: 484424, 120.0: 3779517, 156.0: 3378332, 264.0: 1144966, 192.0: 2453402, 228.0: 1692512, 408.0: 164303, 300.0: 758680, 372.0: 296296, 480.0: 22651, 444.0: 75229})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(hp_dict_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "potential HP dict keys\n",
    "400 and over\n",
    "320 to 400\n",
    "240 to 320\n",
    "160 to 240\n",
    "80 to 160\n",
    "0 to 80\n",
    "\n",
    "\n",
    "dmg values\n",
    "0 to 80\n",
    "80 to 160\n",
    "160 to 240\n",
    "240 to 320\n",
    "320 to 400\n",
    "400 to 480\n",
    "480 to 560\n",
    "560 +\n",
    "\n",
    "\n",
    "5x5 would be like\n",
    "0 to 96\n",
    "96 to 192\n",
    "192 to 288\n",
    "288 to 384\n",
    "384 to 480\n",
    "\n",
    "then for dmg values could do like\n",
    "0 to 120\n",
    "120 to 240\n",
    "240 to 360\n",
    "360 to 480\n",
    "480 +\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "480 / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(6**3 * 8**4)\n",
    "print(6*6*6*8*8*8*8)\n",
    "\n",
    "print(5**4 * 5**6)\n",
    "\n",
    "print(4**4 * 4**6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for a in range(3,9):\n",
    "    for b in range(3,10):\n",
    "        print(a, b, (a**3)*(b**4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(dmg_dict_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(hp_dict_count), len(dmg_dict_count))\n",
    "print(11*11*11 * 67*67*67*67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(11**6 + 67**18 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can then put into pandas and see the distribution of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
